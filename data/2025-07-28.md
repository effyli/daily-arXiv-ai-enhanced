<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 36]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.AI](#cs.AI) [Total: 15]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Specification Self-Correction: Mitigating In-Context Reward Hacking Through Test-Time Refinement](https://arxiv.org/abs/2507.18742)
*Víctor Gallego*

Main category: cs.CL

TL;DR: SSC allows LMs to identify and fix flaws in their guiding specifications during inference, significantly reducing reward hacking.


<details>
  <summary>Details</summary>
Motivation: Address the vulnerability of language models to reward hacking due to flawed specifications.

Method: A multi-step inference framework where the model critiques and revises its own specification before generating the final response.

Result: SSC reduces reward hacking by over 90% across various tasks and models, leading to more aligned behavior.

Conclusion: Self-correction at inference time improves model robustness without needing weight changes.

Abstract: Language models (LMs) are susceptible to in-context reward hacking, where
they exploit flaws in tainted or faulty written specifications or rubrics to
achieve high scores without fulfilling the user's true intent. We introduce
Specification Self-Correction (SSC), a novel, test-time framework that enables
an LM to identify and correct flaws within its own guiding specification. SSC
employs a multi-step inference process where the model first generates a
response based on a potentially tainted specification, critiques its output,
and then revises the specification itself to remove the exploitable loophole. A
final, more robust response is then generated using this self-corrected
specification. Across experiments spanning creative writing and agentic coding
tasks with several LMs, we demonstrate that while models initially game tainted
specifications in 50-70\% of cases, the SSC process reduces this vulnerability
by over 90\%. This dynamic repair occurs at inference time, requires no weight
modification, and leads to more robustly aligned model behavior. Code at
https://github.com/vicgalle/specification-self-correction .

</details>


### [2] [The Role of Orthographic Consistency in Multilingual Embedding Models for Text Classification in Arabic-Script Languages](https://arxiv.org/abs/2507.18762)
*Abdulhady Abas Abdullah,Amir H. Gandomi,Tarik A Rashid,Seyedali Mirjalili,Laith Abualigah,Milena Živković,Hadi Veisi*

Main category: cs.CL

TL;DR: Introducing AS-RoBERTa models tailored to Arabic-script languages, outperforming general models by focusing on script-specific pre-training.


<details>
  <summary>Details</summary>
Motivation: Many multilingual models lack effectiveness for languages sharing scripts but differing culturally and orthographically.

Method: Pre-training four language-specific RoBERTa models emphasizing script features, followed by fine-tuning on classification tasks.

Result: AS-RoBERTa models outperform mBERT and XLM-RoBERTa by 2-5 percentage points, with ablation studies highlighting the importance of script-focused pre-training.

Conclusion: Script-aware pre-training enhances model performance for Arabic-script languages and suggests avenues for further tailored language modeling.

Abstract: In natural language processing, multilingual models like mBERT and
XLM-RoBERTa promise broad coverage but often struggle with languages that share
a script yet differ in orthographic norms and cultural context. This issue is
especially notable in Arabic-script languages such as Kurdish Sorani, Arabic,
Persian, and Urdu. We introduce the Arabic Script RoBERTa (AS-RoBERTa) family:
four RoBERTa-based models, each pre-trained on a large corpus tailored to its
specific language. By focusing pre-training on language-specific script
features and statistics, our models capture patterns overlooked by
general-purpose models. When fine-tuned on classification tasks, AS-RoBERTa
variants outperform mBERT and XLM-RoBERTa by 2 to 5 percentage points. An
ablation study confirms that script-focused pre-training is central to these
gains. Error analysis using confusion matrices shows how shared script traits
and domain-specific content affect performance. Our results highlight the value
of script-aware specialization for languages using the Arabic script and
support further work on pre-training strategies rooted in script and language
specificity.

</details>


### [3] [ylmmcl at Multilingual Text Detoxification 2025: Lexicon-Guided Detoxification and Classifier-Gated Rewriting](https://arxiv.org/abs/2507.18769)
*Nicole Lai-Lopez,Lusha Wang,Su Yuan,Liza Zhang*

Main category: cs.CL

TL;DR: The paper presents a multilingual detoxification pipeline that combines lexicon-guided tagging, fine-tuned sequence-to-sequence models, and classifier gatekeeping, outperforming baselines and achieving high scores in the PAN-2025 competition.


<details>
  <summary>Details</summary>
Motivation: To improve multilingual text detoxification by leveraging explicit toxic word annotations and integrating multiple sophisticated techniques, aiming for better generalization and performance.

Method: Combining lexicon-guided tagging, a fine-tuned seq2seq model (s-nlp/mt0-xl-detox-orpo), and an iterative classifier-based gatekeeping mechanism.

Result: Achieved top performance with a STA of 0.922, J score of 0.612, and xCOMET scores around 0.79, outperforming baseline methods across multiple languages.

Conclusion: The approach enhances detoxification performance in multilingual settings, demonstrating the benefits of explicit toxic word guidance and integrated techniques, though with some trade-offs in similarity metrics.

Abstract: In this work, we introduce our solution for the Multilingual Text
Detoxification Task in the PAN-2025 competition for the ylmmcl team: a robust
multilingual text detoxification pipeline that integrates lexicon-guided
tagging, a fine-tuned sequence-to-sequence model (s-nlp/mt0-xl-detox-orpo) and
an iterative classifier-based gatekeeping mechanism. Our approach departs from
prior unsupervised or monolingual pipelines by leveraging explicit toxic word
annotation via the multilingual_toxic_lexicon to guide detoxification with
greater precision and cross-lingual generalization. Our final model achieves
the highest STA (0.922) from our previous attempts, and an average official J
score of 0.612 for toxic inputs in both the development and test sets. It also
achieved xCOMET scores of 0.793 (dev) and 0.787 (test). This performance
outperforms baseline and backtranslation methods across multiple languages, and
shows strong generalization in high-resource settings (English, Russian,
French). Despite some trade-offs in SIM, the model demonstrates consistent
improvements in detoxification strength. In the competition, our team achieved
ninth place with a score of 0.612.

</details>


### [4] [Evaluating Code-Mixing in LLMs Across 18 Languages](https://arxiv.org/abs/2507.18791)
*Yilun Yang,Yekun Chai*

Main category: cs.CL

TL;DR: This paper evaluates large language models (LLMs) on their ability to handle code-mixed data across multiple languages, highlighting current limitations and proposing a new data generation method using GPT-4.


<details>
  <summary>Details</summary>
Motivation: The need to better assess and improve LLMs' performance on code-mixing, a common linguistic practice among multilingual users, which is inadequately covered by existing benchmarks.

Method: The study conducts a comprehensive evaluation of LLMs across 18 languages and introduces a novel synthetic data generation approach combining word substitution with GPT-4 prompting.

Result: LLMs consistently underperform on code-mixed data, especially involving multiple language families. Enhancement strategies include increasing training data, model scale, and few-shot learning techniques.

Conclusion: Improving LLMs' capabilities in code-mixing requires better training data, larger models, and more effective few-shot learning, to address current challenges highlighted by the evaluation.

Abstract: Code-mixing, the practice of switching between languages within a
conversation, presents unique challenges for traditional natural language
processing. Existing benchmarks, such as LinCE and GLUECoS, are limited by
narrow language pairings and tasks, failing to adequately evaluate the
code-mixing capabilities of large language models (LLMs). Despite the
significance of code-mixing for multilingual users, research on LLMs in this
context remains limited. Additionally, current methods for generating
code-mixed data are underdeveloped. In this paper, we conduct a comprehensive
evaluation of LLMs' performance on code-mixed data across 18 languages from
seven language families. We also propose a novel approach for generating
synthetic code-mixed texts by combining word substitution with GPT-4 prompting.
Our analysis reveals consistent underperformance of LLMs on code-mixed datasets
involving multiple language families. We suggest that improvements in training
data size, model scale, and few-shot learning could enhance their performance.

</details>


### [5] [CueBuddy: helping non-native English speakers navigate English-centric STEM education](https://arxiv.org/abs/2507.18827)
*Pranav Gupta*

Main category: cs.CL

TL;DR: CueBuddy offers real-time lexical cues via technical keyword spotting and glossary lookup to aid STEM students in understanding English jargon during lectures.


<details>
  <summary>Details</summary>
Motivation: Addressing the language barrier faced by STEM students in low-resource settings, particularly with complex English terminology.

Method: Development of CueBuddy, which uses real-time technical keyword spotting and multilingual glossary lookup to provide lexical cues without disrupting lecture focus.

Result: A system that supplies real-time lexical cues to help students understand complex English terms during lectures, with identified limitations and future potential.

Conclusion: CueBuddy shows promise as an assistive tool for STEM education in multilingual settings, though further developments are needed.

Abstract: Students across the world in STEM classes, especially in the Global South,
fall behind their peers who are more fluent in English, despite being at par
with them in terms of scientific prerequisites. While many of them are able to
follow everyday English at ease, key terms in English stay challenging. In most
cases, such students have had most of their course prerequisites in a lower
resource language. Live speech translation to lower resource languages is a
promising area of research, however, models for speech translation can be too
expensive on a large scale and often struggle with technical content. In this
paper, we describe CueBuddy, which aims to remediate these issues by providing
real-time "lexical cues" through technical keyword spotting along real-time
multilingual glossary lookup to help students stay up to speed with complex
English jargon without disrupting their concentration on the lecture. We also
describe the limitations and future extensions of our approach.

</details>


### [6] [PrismRAG: Boosting RAG Factuality with Distractor Resilience and Strategized Reasoning](https://arxiv.org/abs/2507.18857)
*Mohammad Kachuee,Teja Gollapudi,Minseok Kim,Yin Huang,Kai Sun,Xiao Yang,Jiaqi Wang,Nirav Shah,Yue Liu,Aaron Colak,Anuj Kumar,Wen-tau Yih,Xin Luna Dong*

Main category: cs.CL

TL;DR: PrismRAG enhances retrieval-augmented generation by training with distractor-aware QA pairs and emphasizing reasoning, resulting in significant factuality improvements.


<details>
  <summary>Details</summary>
Motivation: To address limitations of RAG in confusing contexts and complex reasoning.

Method: Fine-tuning with distractor-aware QA pairs and fostering reasoning habits in LLMs.

Result: Improves average factuality by 5.4%, outperforming current best methods across multiple benchmarks.

Conclusion: PrismRAG effectively improves RAG performance by better training and reasoning strategies.

Abstract: Retrieval-augmented generation (RAG) often falls short when retrieved context
includes confusing semi-relevant passages, or when answering questions require
deep contextual understanding and reasoning. We propose an efficient
fine-tuning framework, called PrismRAG, that (i) trains the model with
distractor-aware QA pairs mixing gold evidence with subtle distractor passages,
and (ii) instills reasoning-centric habits that make the LLM plan, rationalize,
and synthesize without relying on extensive human engineered instructions.
Evaluated across 12 open-book RAG QA benchmarks spanning diverse application
domains and scenarios, PrismRAG improves average factuality by 5.4%,
outperforming state-of-the-art solutions.

</details>


### [7] [MindFlow+: A Self-Evolving Agent for E-Commerce Customer Service](https://arxiv.org/abs/2507.18884)
*Ming Gong,Xucheng Huang,Ziheng Xu,Vijayan K. Asari*

Main category: cs.CL

TL;DR: MindFlow+ is a self-evolving e-commerce dialogue agent that combines LLMs, imitation learning, and reinforcement learning, using data-centric mechanisms to improve response relevance and task accuracy.


<details>
  <summary>Details</summary>
Motivation: Traditional intent-based systems struggle with dynamic, multi-turn customer interactions in e-commerce, necessitating more adaptive dialogue systems.

Method: MindFlow+ utilizes large language models, tool-augmented demonstration construction, and reward-conditioned data modeling, guided by offline RL, to enhance domain-specific dialogue capabilities.

Result: MindFlow+ outperforms baseline models in relevance, flexibility, and accuracy, validated through real-world e-commerce conversation experiments. Introduces AI Contribution Ratio as a new metric to assess AI involvement.

Conclusion: Combining LLMs, tool reasoning, and reward-guided learning is effective for developing domain-specific, context-aware dialogue systems in e-commerce.

Abstract: High-quality dialogue is crucial for e-commerce customer service, yet
traditional intent-based systems struggle with dynamic, multi-turn
interactions. We present MindFlow+, a self-evolving dialogue agent that learns
domain-specific behavior by combining large language models (LLMs) with
imitation learning and offline reinforcement learning (RL). MindFlow+
introduces two data-centric mechanisms to guide learning: tool-augmented
demonstration construction, which exposes the model to knowledge-enhanced and
agentic (ReAct-style) interactions for effective tool use; and
reward-conditioned data modeling, which aligns responses with task-specific
goals using reward signals. To evaluate the model's role in response
generation, we introduce the AI Contribution Ratio, a novel metric quantifying
AI involvement in dialogue. Experiments on real-world e-commerce conversations
show that MindFlow+ outperforms strong baselines in contextual relevance,
flexibility, and task accuracy. These results demonstrate the potential of
combining LLMs tool reasoning, and reward-guided learning to build
domain-specialized, context-aware dialogue systems.

</details>


### [8] [NUTMEG: Separating Signal From Noise in Annotator Disagreement](https://arxiv.org/abs/2507.18890)
*Jonathan Ivey,Susan Gauch,David Jurgens*

Main category: cs.CL

TL;DR: NUTMEG, a Bayesian model, effectively distinguishes between noise and genuine disagreement in crowdsourced annotations, improving the quality of training data and downstream NLP performance.


<details>
  <summary>Details</summary>
Motivation: Address the challenge of conflicting crowdsourced annotations in NLP datasets by distinguishing between noise and systematic disagreement.

Method: Introduce NUTMEG, a Bayesian model that incorporates annotator background information to filter noisy annotations while preserving meaningful disagreements.

Result: NUTMEG outperforms traditional aggregation methods in synthetic tests and improves downstream NLP model performance.

Conclusion: Accounting for annotator background and systematic disagreement enhances the quality of human-labeled data for NLP tasks.

Abstract: NLP models often rely on human-labeled data for training and evaluation. Many
approaches crowdsource this data from a large number of annotators with varying
skills, backgrounds, and motivations, resulting in conflicting annotations.
These conflicts have traditionally been resolved by aggregation methods that
assume disagreements are errors. Recent work has argued that for many tasks
annotators may have genuine disagreements and that variation should be treated
as signal rather than noise. However, few models separate signal and noise in
annotator disagreement. In this work, we introduce NUTMEG, a new Bayesian model
that incorporates information about annotator backgrounds to remove noisy
annotations from human-labeled training data while preserving systematic
disagreements. Using synthetic data, we show that NUTMEG is more effective at
recovering ground-truth from annotations with systematic disagreement than
traditional aggregation methods. We provide further analysis characterizing how
differences in subpopulation sizes, rates of disagreement, and rates of spam
affect the performance of our model. Finally, we demonstrate that downstream
models trained on NUTMEG-aggregated data significantly outperform models
trained on data from traditionally aggregation methods. Our results highlight
the importance of accounting for both annotator competence and systematic
disagreements when training on human-labeled data.

</details>


### [9] [REPRO-Bench: Can Agentic AI Systems Assess the Reproducibility of Social Science Research?](https://arxiv.org/abs/2507.18901)
*Chuxuan Hu,Liyun Zhang,Yeji Lim,Aum Wadhwani,Austin Peters,Daniel Kang*

Main category: cs.CL

TL;DR: The paper introduces REPRO-Bench, a benchmark for testing AI agents' ability to assess the reproducibility of social science papers, revealing current AI limitations and proposing an improved agent.


<details>
  <summary>Details</summary>
Motivation: To automate and improve the reproducibility assessment process in social sciences, which is currently manual and costly.

Method: Developing REPRO-Bench with real-world complexity, testing existing AI agents, and creating REPRO-Agent based on empirical insights.

Result: Existing AI agents perform poorly (best at 21.4%), but the new REPRO-Agent significantly improves accuracy by 71%.

Conclusion: Advanced AI agents are needed for automated reproducibility assessment, and REPRO-Bench serves as a valuable benchmark.

Abstract: Assessing the reproducibility of social science papers is essential for
promoting rigor in research processes, but manual assessment is costly. With
recent advances in agentic AI systems (i.e., AI agents), we seek to evaluate
their capability to automate this process. However, existing benchmarks for
reproducing research papers (1) focus solely on reproducing results using
provided code and data without assessing their consistency with the paper, (2)
oversimplify real-world scenarios, and (3) lack necessary diversity in data
formats and programming languages. To address these issues, we introduce
REPRO-Bench, a collection of 112 task instances, each representing a social
science paper with a publicly available reproduction report. The agents are
tasked with assessing the reproducibility of the paper based on the original
paper PDF and the corresponding reproduction package. REPRO-Bench features
end-to-end evaluation tasks on the reproducibility of social science papers
with complexity comparable to real-world assessments. We evaluate three
representative AI agents on REPRO-Bench, with the best-performing agent
achieving an accuracy of only 21.4%. Building on our empirical analysis, we
develop REPRO-Agent, which improves the highest accuracy achieved by existing
agents by 71%. We conclude that more advanced AI agents should be developed to
automate real-world reproducibility assessment. REPRO-Bench is publicly
available at https://github.com/uiuc-kang-lab/REPRO-Bench.

</details>


### [10] [SLoW: Select Low-frequency Words! Automatic Dictionary Selection for Translation on Large Language Models](https://arxiv.org/abs/2507.18902)
*Hongyuan Lu,Zixuan Li,Zefan Zhang,Wai Lam*

Main category: cs.CL

TL;DR: The paper introduces ADS and SLoW, methods for automatically selecting low-frequency dictionaries to improve translation efficiency and performance across many languages without requiring training data.


<details>
  <summary>Details</summary>
Motivation: To enhance translation in underrepresented languages while reducing costs and data dependence.

Method: Automatic dictionary selection (ADS) using SLoW, which chooses dictionaries based on low-frequency words without needing training data.

Result: SLoW outperforms baselines, saving tokens and improving translation in many cases, even surpassing full dictionary methods.

Conclusion: SLoW effectively balances translation quality and token consumption, facilitating multilingual translation with minimal data requirements.

Abstract: There are more than 7,000 languages around the world, and current Large
Language Models (LLMs) only support hundreds of languages. Dictionary-based
prompting methods can enhance translation on them, but most methods use all the
available dictionaries, which could be expensive. Instead, it will be flexible
to have a trade-off between token consumption and translation performance. This
paper proposes a novel task called \textbf{A}utomatic \textbf{D}ictionary
\textbf{S}election (\textbf{ADS}). The goal of the task is to automatically
select which dictionary to use to enhance translation. We propose a novel and
effective method which we call \textbf{S}elect \textbf{Lo}w-frequency
\textbf{W}ords! (\textbf{SLoW}) which selects those dictionaries that have a
lower frequency. Our methods have unique advantages. First, there is no need
for access to the training data for frequency estimation (which is usually
unavailable). Second, it inherits the advantage of dictionary-based methods,
where no additional tuning is required on LLMs. Experimental results on 100
languages from FLORES indicate that SLoW surpasses strong baselines, and it can
obviously save token usage, with many languages even surpassing the translation
performance of the full dictionary baseline.\footnote{A shocking fact is that
there is no need to use the actual training data (often unobtainable) for
frequency estimation, and an estimation frequency obtained using public
resources is still apparently effective in improving translation with ChatGPT
and Llama, and DeepSeek.}\footnote{Code and data available upon publication.}

</details>


### [11] [Large language models provide unsafe answers to patient-posed medical questions](https://arxiv.org/abs/2507.18905)
*Rachel L. Draelos,Samina Afreen,Barbara Blasko,Tiffany Brazile,Natasha Chase,Dimple Desai,Jessica Evert,Heather L. Gardner,Lauren Herrmann,Aswathy Vaikom House,Stephanie Kass,Marianne Kavan,Kirshma Khemani,Amanda Koire,Lauren M. McDonald,Zahraa Rabeeah,Amy Shah*

Main category: cs.CL

TL;DR: Large language model chatbots exhibit significant safety concerns, with substantial variation in problematic responses across different models, potentially risking patient harm.


<details>
  <summary>Details</summary>
Motivation: The widespread use of LLM chatbots for medical advice necessitates an evaluation of their safety to protect patients.

Method: A physician-led red-teaming study comparing four publicly available chatbots on a new dataset, evaluating 888 responses to 222 patient questions using both quantitative and qualitative analysis.

Result: Significant differences in safety performance were found; problematic responses ranged from 21.6% to 43.2%, with unsafe responses up to 13%.

Conclusion: Many patients may be receiving unsafe advice, indicating a need for improvements to ensure the clinical safety of these tools.

Abstract: Millions of patients are already using large language model (LLM) chatbots
for medical advice on a regular basis, raising patient safety concerns. This
physician-led red-teaming study compares the safety of four publicly available
chatbots--Claude by Anthropic, Gemini by Google, GPT-4o by OpenAI, and
Llama3-70B by Meta--on a new dataset, HealthAdvice, using an evaluation
framework that enables quantitative and qualitative analysis. In total, 888
chatbot responses are evaluated for 222 patient-posed advice-seeking medical
questions on primary care topics spanning internal medicine, women's health,
and pediatrics. We find statistically significant differences between chatbots.
The rate of problematic responses varies from 21.6 percent (Claude) to 43.2
percent (Llama), with unsafe responses varying from 5 percent (Claude) to 13
percent (GPT-4o, Llama). Qualitative results reveal chatbot responses with the
potential to lead to serious patient harm. This study suggests that millions of
patients could be receiving unsafe medical advice from publicly available
chatbots, and further work is needed to improve the clinical safety of these
powerful tools.

</details>


### [12] [A Systematic Review of Key Retrieval-Augmented Generation (RAG) Systems: Progress, Gaps, and Future Directions](https://arxiv.org/abs/2507.18910)
*Agada Joseph Oche,Ademola Glory Folashade,Tirthankar Ghosal,Arpan Biswas*

Main category: cs.CL

TL;DR: Comprehensive review of Retrieval-Augmented Generation (RAG), exploring its evolution, technical core, applications, challenges, and future directions.


<details>
  <summary>Details</summary>
Motivation: To address limitations like hallucinations and outdated knowledge in language models by integrating retrieval mechanisms.

Method: Systematic review of RAG's development, technical components, performance benchmarking, and practical deployment issues.

Result: Identified key milestones, evaluated implementations, and analyzed persistent challenges and emerging solutions.

Conclusion: RAG is evolving with innovations that promise more reliable and efficient NLP systems, although challenges remain to be addressed.

Abstract: Retrieval-Augmented Generation (RAG) represents a major advancement in
natural language processing (NLP), combining large language models (LLMs) with
information retrieval systems to enhance factual grounding, accuracy, and
contextual relevance. This paper presents a comprehensive systematic review of
RAG, tracing its evolution from early developments in open domain question
answering to recent state-of-the-art implementations across diverse
applications. The review begins by outlining the motivations behind RAG,
particularly its ability to mitigate hallucinations and outdated knowledge in
parametric models. Core technical components-retrieval mechanisms,
sequence-to-sequence generation models, and fusion strategies are examined in
detail. A year-by-year analysis highlights key milestones and research trends,
providing insight into RAG's rapid growth. The paper further explores the
deployment of RAG in enterprise systems, addressing practical challenges
related to retrieval of proprietary data, security, and scalability. A
comparative evaluation of RAG implementations is conducted, benchmarking
performance on retrieval accuracy, generation fluency, latency, and
computational efficiency. Persistent challenges such as retrieval quality,
privacy concerns, and integration overhead are critically assessed. Finally,
the review highlights emerging solutions, including hybrid retrieval
approaches, privacy-preserving techniques, optimized fusion strategies, and
agentic RAG architectures. These innovations point toward a future of more
reliable, efficient, and context-aware knowledge-intensive NLP systems.

</details>


### [13] [Mining Contextualized Visual Associations from Images for Creativity Understanding](https://arxiv.org/abs/2507.18915)
*Ananya Sahu,Amith Ananthram,Kathleen McKeown*

Main category: cs.CL

TL;DR: This paper introduces a method for mining contextualized associations to generate creative, abstract captions for images, enhancing vision-language models like CLIP.


<details>
  <summary>Details</summary>
Motivation: To improve the ability of vision-language models to understand and describe creative and abstract visual content.

Method: Mining contextualized associations for salient visual elements to generate high-quality, increasingly abstract creative captions, resulting in a new dataset of visual associations and captions.

Result: Created a dataset of 1.7m creative captions with human-validated visual grounding, and improved zero-shot image-text retrieval in poetry and metaphor visualization tasks.

Conclusion: The dataset and method enable better understanding of abstract visual concepts, benefiting creative domain applications and open community use.

Abstract: Understanding another person's creative output requires a shared language of
association. However, when training vision-language models such as CLIP, we
rely on web-scraped datasets containing short, predominantly literal, alt-text.
In this work, we introduce a method for mining contextualized associations for
salient visual elements in an image that can scale to any unlabeled dataset.
Given an image, we can use these mined associations to generate high quality
creative captions at increasing degrees of abstraction. With our method, we
produce a new dataset of visual associations and 1.7m creative captions for the
images in MSCOCO. Human evaluation confirms that these captions remain visually
grounded while exhibiting recognizably increasing abstraction. Moreover,
fine-tuning a visual encoder on this dataset yields meaningful improvements in
zero-shot image-text retrieval in two creative domains: poetry and metaphor
visualization. We release our dataset, our generation code and our models for
use by the broader community.

</details>


### [14] [Uncovering Cross-Linguistic Disparities in LLMs using Sparse Autoencoders](https://arxiv.org/abs/2507.18918)
*Richmond Sin Jing Xuan,Jalil Huseynov,Yang Zhang*

Main category: cs.CL

TL;DR: Fine-tuning multilingual LLMs with activation-aware methods improves performance for low-resource languages.


<details>
  <summary>Details</summary>
Motivation: To address the performance disparity of medium to low resource languages in multilingual LLMs across benchmarks.

Method: Analyzing activation patterns with SAEs and applying activation-aware fine-tuning via LoRA.

Result: Significant activation improvements in low-resource languages and modest performance gains on benchmarks.

Conclusion: Activation alignment through fine-tuning is crucial for enhancing multilingual LLM performance.

Abstract: Multilingual large language models (LLMs) exhibit strong cross-linguistic
generalization, yet medium to low resource languages underperform on common
benchmarks such as ARC-Challenge, MMLU, and HellaSwag. We analyze activation
patterns in Gemma-2-2B across all 26 residual layers and 10 languages: Chinese
(zh), Russian (ru), Spanish (es), Italian (it), medium to low resource
languages including Indonesian (id), Catalan (ca), Marathi (mr), Malayalam
(ml), and Hindi (hi), with English (en) as the reference. Using Sparse
Autoencoders (SAEs), we reveal systematic disparities in activation patterns.
Medium to low resource languages receive up to 26.27 percent lower activations
in early layers, with a persistent gap of 19.89 percent in deeper layers. To
address this, we apply activation-aware fine-tuning via Low-Rank Adaptation
(LoRA), leading to substantial activation gains, such as 87.69 percent for
Malayalam and 86.32 percent for Hindi, while maintaining English retention at
approximately 91 percent. After fine-tuning, benchmark results show modest but
consistent improvements, highlighting activation alignment as a key factor in
enhancing multilingual LLM performance.

</details>


### [15] [LLaVA-NeuMT: Selective Layer-Neuron Modulation for Efficient Multilingual Multimodal Translation](https://arxiv.org/abs/2507.18940)
*Jingxuan Wei,Caijun Jia,Qi Chen,Yujun Cai,Linzhuang Sun,Xiangxiang Zhang,Gaowei Wu,Bihui Yu*

Main category: cs.CL

TL;DR: LLaVA-NeuMT improves multimodal multilingual translation by modeling language-specific and agnostic features with selective layer and neuron adaptation, outperforming full fine-tuning methods.


<details>
  <summary>Details</summary>
Motivation: Enhance multimodal machine translation across multiple languages by reducing cross-lingual interference.

Method: Layer selection mechanism and neuron-level adaptation for language-specific and agnostic representation modeling.

Result: Surpassed full fine-tuning approaches and achieved state-of-the-art results while fine-tuning only 40% of parameters.

Conclusion: The proposed approach offers an efficient, scalable solution for cross-lingual adaptation in multimodal translation by focusing on critical layers and neurons.

Abstract: Multimodal Machine Translation (MMT) enhances translation quality by
incorporating visual context, helping to resolve textual ambiguities. While
existing MMT methods perform well in bilingual settings, extending them to
multilingual translation remains challenging due to cross-lingual interference
and ineffective parameter-sharing strategies. To address this, we propose
LLaVA-NeuMT, a novel multimodal multilingual translation framework that
explicitly models language-specific and language-agnostic representations to
mitigate multilingual interference. Our approach consists of a layer selection
mechanism that identifies the most informative layers for different language
pairs and a neuron-level adaptation strategy that dynamically selects
language-specific and agnostic neurons to improve translation quality while
reducing redundancy. We conduct extensive experiments on the M3-Multi30K and
M3-AmbigCaps datasets, demonstrating that LLaVA-NeuMT, while fine-tuning only
40\% of the model parameters, surpasses full fine-tuning approaches and
ultimately achieves SOTA results on both datasets. Our analysis further
provides insights into the importance of selected layers and neurons in
multimodal multilingual adaptation, offering an efficient and scalable solution
to cross-lingual adaptation in multimodal translation.

</details>


### [16] [Legal Document Summarization: Enhancing Judicial Efficiency through Automation Detection](https://arxiv.org/abs/2507.18952)
*Yongjie Li,Ruilin Nong,Jianan Liu,Lucas Evans*

Main category: cs.CL

TL;DR: This paper presents a machine learning-based framework for automating legal document summarization, improving efficiency and reducing errors in judicial review.


<details>
  <summary>Details</summary>
Motivation: To enhance judicial efficiency by automating the extraction of key information from legal texts.

Method: Using advanced NLP and machine learning algorithms to identify and summarize essential data in legal documents.

Result: The approach produces high-quality summaries that maintain content integrity and significantly improve processing times.

Conclusion: Automation in legal document analysis can significantly streamline judicial workflows and improve accuracy.

Abstract: Legal document summarization represents a significant advancement towards
improving judicial efficiency through the automation of key information
detection. Our approach leverages state-of-the-art natural language processing
techniques to meticulously identify and extract essential data from extensive
legal texts, which facilitates a more efficient review process. By employing
advanced machine learning algorithms, the framework recognizes underlying
patterns within judicial documents to create precise summaries that encapsulate
the crucial elements. This automation alleviates the burden on legal
professionals, concurrently reducing the likelihood of overlooking vital
information that could lead to errors. Through comprehensive experiments
conducted with actual legal datasets, we demonstrate the capability of our
method to generate high-quality summaries while preserving the integrity of the
original content and enhancing processing times considerably. The results
reveal marked improvements in operational efficiency, allowing legal
practitioners to direct their efforts toward critical analytical and
decision-making activities instead of manual reviews. This research highlights
promising technology-driven strategies that can significantly alter workflow
dynamics within the legal sector, emphasizing the role of automation in
refining judicial processes.

</details>


### [17] [A Similarity Measure for Comparing Conversational Dynamics](https://arxiv.org/abs/2507.18956)
*Sang Min Jung,Kaixiang Zhang,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: This paper introduces a similarity measure for comparing the overall interactional dynamics of conversations, validated through a robustness framework and applied to analyze conversational dynamics in an online community.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a robust automated method for comparing conversations based on their interactional patterns, which current tools lack.

Method: Designing a similarity measure for conversations, validating its robustness and sensitivity, and applying it to analyze online community conversations.

Result: The measure effectively captures dynamic differences and reveals insights about situational power in online conversations.

Conclusion: The proposed similarity measure is a useful tool for holistic conversational analysis and understanding interactional patterns.

Abstract: The quality of a conversation goes beyond the individual quality of each
reply, and instead emerges from how these combine into interactional patterns
that give the conversation its distinctive overall "shape". However, there is
no robust automated method for comparing conversations in terms of their
overall interactional dynamics. Such methods could enhance the analysis of
conversational data and help evaluate conversational agents more holistically.
  In this work, we introduce a similarity measure for comparing conversations
with respect to their dynamics. We design a validation framework for testing
the robustness of the metric in capturing differences in conversation dynamics
and for assessing its sensitivity to the topic of the conversations. Finally,
to illustrate the measure's utility, we use it to analyze conversational
dynamics in a large online community, bringing new insights into the role of
situational power in conversations.

</details>


### [18] [A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation](https://arxiv.org/abs/2507.18973)
*Bohan Yao,Vikas Yadav*

Main category: cs.CL

TL;DR: Multi-TAG is a novel framework that enhances large language models' mathematical reasoning by concurrently invoking and aggregating multiple tools, leading to significant performance improvements on complex math benchmarks.


<details>
  <summary>Details</summary>
Motivation: To improve the reasoning capabilities of LLMs on complex mathematical problems that require multi-step reasoning.

Method: Guiding LLMs to simultaneously invoke multiple external tools and aggregate their outputs without fine-tuning.

Result: Achieves 6.0% to 7.5% improvements over state-of-the-art methods on challenging mathematical benchmarks.

Conclusion: Multi-TAG effectively boosts LLM performance on complex math tasks in a fine-tuning-free, inference-only manner.

Abstract: Augmenting large language models (LLMs) with external tools is a promising
avenue for developing high-performance mathematical reasoning systems. Prior
tool-augmented approaches typically finetune an LLM to select and invoke a
single tool at each reasoning step and show promising results on simpler math
reasoning benchmarks such as GSM8K. However, these approaches struggle with
more complex math problems that require precise reasoning over multiple steps.
To address this limitation, in this work, we propose Multi-TAG, a Multi-Tool
AGgregation-based framework. Instead of relying on a single tool, Multi-TAG
guides an LLM to concurrently invoke multiple tools at each reasoning step. It
then aggregates their diverse outputs to verify and refine the reasoning
process, enhancing solution robustness and accuracy. Notably, Multi-TAG is a
finetuning-free, inference-only framework, making it readily applicable to any
LLM backbone, including large open-weight models which are computationally
expensive to finetune and proprietary frontier models which cannot be finetuned
with custom recipes. We evaluate Multi-TAG on four challenging benchmarks:
MATH500, AIME, AMC, and OlympiadBench. Across both open-weight and
closed-source LLM backbones, Multi-TAG consistently and substantially
outperforms state-of-the-art baselines, achieving average improvements of 6.0%
to 7.5% over state-of-the-art baselines.

</details>


### [19] [Arg-LLaDA: Argument Summarization via Large Language Diffusion Models and Sufficiency-Aware Refinement](https://arxiv.org/abs/2507.19081)
*Hao Li,Yizheng Sun,Viktor Schlegel,Kailai Yang,Riza Batista-Navarro,Goran Nenadic*

Main category: cs.CL

TL;DR: Arg-LLaDA is a novel iterative summarization framework that improves debate argument summaries for accuracy, coherence, and conciseness.


<details>
  <summary>Details</summary>
Motivation: To enhance argument summarization by enabling iterative refinement that ensures factual accuracy and structural quality.

Method: A large language diffusion framework with a masking controller and sufficiency-checking module for iterative remasking and regeneration.

Result: Outperformed state-of-the-art models in most automatic metrics and received positive human evaluations on core quality aspects.

Conclusion: Iterative, sufficiency-aware generation significantly improves the quality of argument summaries, making them more faithful, concise, and coherent.

Abstract: Argument summarization aims to generate concise, structured representations
of complex, multi-perspective debates. While recent work has advanced the
identification and clustering of argumentative components, the generation stage
remains underexplored. Existing approaches typically rely on single-pass
generation, offering limited support for factual correction or structural
refinement. To address this gap, we introduce Arg-LLaDA, a novel large language
diffusion framework that iteratively improves summaries via sufficiency-guided
remasking and regeneration. Our method combines a flexible masking controller
with a sufficiency-checking module to identify and revise unsupported,
redundant, or incomplete spans, yielding more faithful, concise, and coherent
outputs. Empirical results on two benchmark datasets demonstrate that Arg-LLaDA
surpasses state-of-the-art baselines in 7 out of 10 automatic evaluation
metrics. In addition, human evaluations reveal substantial improvements across
core dimensions, coverage, faithfulness, and conciseness, validating the
effectiveness of our iterative, sufficiency-aware generation strategy.

</details>


### [20] [Debating Truth: Debate-driven Claim Verification with Multiple Large Language Model Agents](https://arxiv.org/abs/2507.19090)
*Haorui He,Yupeng Li,Dacheng Wen,Reynold Cheng,Francis C. M. Lau*

Main category: cs.CL

TL;DR: DebateCV introduces a debate-driven framework for claim verification using multiple LLM agents, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of single-LLM methods in complex claim verification involving multifaceted evidence.

Method: Employs a debate-driven approach with multiple LLM agents acting as Debaters and a Moderator, complemented by a novel post-training strategy with synthetic debate data.

Result: Outperforms existing claim verification methods, especially with varied evidence quality.

Conclusion: DebateCV effectively enhances claim verification through a debate-based methodology and synthetic data training, contributing a new framework and dataset.

Abstract: Claim verification is critical for enhancing digital literacy. However, the
state-of-the-art single-LLM methods struggle with complex claim verification
that involves multi-faceted evidences. Inspired by real-world fact-checking
practices, we propose DebateCV, the first claim verification framework that
adopts a debate-driven methodology using multiple LLM agents. In our framework,
two Debaters take opposing stances on a claim and engage in multi-round
argumentation, while a Moderator evaluates the arguments and renders a verdict
with justifications. To further improve the performance of the Moderator, we
introduce a novel post-training strategy that leverages synthetic debate data
generated by the zero-shot DebateCV, effectively addressing the scarcity of
real-world debate-driven claim verification data. Experimental results show
that our method outperforms existing claim verification methods under varying
levels of evidence quality. Our code and dataset are publicly available at
https://anonymous.4open.science/r/DebateCV-6781.

</details>


### [21] [Objectifying the Subjective: Cognitive Biases in Topic Interpretations](https://arxiv.org/abs/2507.19117)
*Swapnil Hingmire,Ze Shi Li,Shiyu,Zeng,Ahmed Musa Awon,Luiz Franciscatto Guerra,Neil Ernst*

Main category: cs.CL

TL;DR: The paper studies how users interpret topics in text analysis, proposing a theory based on heuristics and emphasizing the importance of user-centered, bias-aware evaluation methods.


<details>
  <summary>Details</summary>
Motivation: Current evaluation metrics for topic quality lack assessment of how well topics facilitate exploration by users.

Method: User studies with rationales, reflexive thematic analysis, and theory development based on heuristics.

Result: Users interpret topics mainly through heuristics like availability and representativeness; a new interpretation model based on anchoring-and-adjustment heuristic is proposed.

Conclusion: Effective topic evaluation should account for cognitive biases and heuristics, emphasizing ecologically rational user models.

Abstract: Interpretation of topics is crucial for their downstream applications.
State-of-the-art evaluation measures of topic quality such as coherence and
word intrusion do not measure how much a topic facilitates the exploration of a
corpus. To design evaluation measures grounded on a task, and a population of
users, we do user studies to understand how users interpret topics. We propose
constructs of topic quality and ask users to assess them in the context of a
topic and provide rationale behind evaluations. We use reflexive thematic
analysis to identify themes of topic interpretations from rationales. Users
interpret topics based on availability and representativeness heuristics rather
than probability. We propose a theory of topic interpretation based on the
anchoring-and-adjustment heuristic: users anchor on salient words and make
semantic adjustments to arrive at an interpretation. Topic interpretation can
be viewed as making a judgment under uncertainty by an ecologically rational
user, and hence cognitive biases aware user models and evaluation frameworks
are needed.

</details>


### [22] [An Empirical Investigation of Gender Stereotype Representation in Large Language Models: The Italian Case](https://arxiv.org/abs/2507.19156)
*Gioele Giachino,Marco Rondina,Antonio Vetrò,Riccardo Coppola,Juan Carlos De Martin*

Main category: cs.CL

TL;DR: The paper studies gender and professional biases in LLM-generated responses in Italian, revealing that these models often perpetuate stereotypes, with implications for social equity.


<details>
  <summary>Details</summary>
Motivation: To address the concern that LLMs may perpetuate biases, especially in gender and professional contexts.

Method: Experimental analysis using structured prompts related to hierarchical professions in Italian, comparing responses from ChatGPT and Google Gemini.

Result: Models often associate stereotypical roles with gendered pronouns, e.g., 'she' linked to 'assistant' and 'he' to 'manager,' indicating bias.

Conclusion: LLMs showcase biases that could impact social and professional perceptions; further research is necessary to mitigate such biases.

Abstract: The increasing use of Large Language Models (LLMs) in a large variety of
domains has sparked worries about how easily they can perpetuate stereotypes
and contribute to the generation of biased content. With a focus on gender and
professional bias, this work examines in which manner LLMs shape responses to
ungendered prompts, contributing to biased outputs. This analysis uses a
structured experimental method, giving different prompts involving three
different professional job combinations, which are also characterized by a
hierarchical relationship. This study uses Italian, a language with extensive
grammatical gender differences, to highlight potential limitations in current
LLMs' ability to generate objective text in non-English languages. Two popular
LLM-based chatbots are examined, namely OpenAI ChatGPT (gpt-4o-mini) and Google
Gemini (gemini-1.5-flash). Through APIs, we collected a range of 3600
responses. The results highlight how content generated by LLMs can perpetuate
stereotypes. For example, Gemini associated 100% (ChatGPT 97%) of 'she'
pronouns to the 'assistant' rather than the 'manager'. The presence of bias in
AI-generated text can have significant implications in many fields, such as in
the workplaces or in job selections, raising ethical concerns about its use.
Understanding these risks is pivotal to developing mitigation strategies and
assuring that AI-based systems do not increase social inequalities, but rather
contribute to more equitable outcomes. Future research directions include
expanding the study to additional chatbots or languages, refining prompt
engineering methods or further exploiting a larger experimental base.

</details>


### [23] [Can Small-Scale Data Poisoning Exacerbate Dialect-Linked Biases in Large Language Models?](https://arxiv.org/abs/2507.19195)
*Chaymaa Abbas,Mariette Awad,Razane Tajeddine*

Main category: cs.CL

TL;DR: Data poisoning amplifies social biases, especially for African American Vernacular English in large language models, highlighting the need for dialect-aware evaluation and debiasing.


<details>
  <summary>Details</summary>
Motivation: Address social biases in LLMs and how dialectal variation interacts with data poisoning.

Method: Analyzed LLM responses to poisoned data across dialects (AAVE vs SAE) using small/medium LLaMA models and GPT-4o for fairness auditing.

Result: Poisoned data significantly increases toxicity in AAVE inputs; larger models show greater bias amplification; GPT-4o detects stereotypical patterns linked to AAVE.

Conclusion: Necessity for dialect-aware evaluation, targeted debiasing, and responsible training to mitigate biases in LLMs.

Abstract: Despite the ongoing improvements in the design of large language models
(LLMs) to foster inclusion and balanced responses, these systems remain
susceptible to encoding and amplifying social biases. This study examines how
dialectal variation, specifically African American Vernacular English (AAVE)
versus Standard American English (SAE), interacts with data poisoning to
influence toxicity in outputs. Using both small- and medium-scale LLaMA models,
we show that even minimal exposure to poisoned data significantly increases
toxicity for AAVE inputs, while it remains comparatively unaffected for SAE.
Larger models exhibit a more significant amplification effect which suggests
heightened susceptibility with scale. To further assess these disparities, we
employed GPT-4o as a fairness auditor, which identified harmful stereotypical
patterns disproportionately tied to AAVE inputs, including portrayals of
aggression, criminality, and intellectual inferiority. These findings
underscore the compounding impact of data poisoning and dialectal bias and
emphasize the need for dialect-aware evaluation, targeted debiasing
interventions, and socially responsible training protocols during development.

</details>


### [24] [How Much Do Large Language Model Cheat on Evaluation? Benchmarking Overestimation under the One-Time-Pad-Based Framework](https://arxiv.org/abs/2507.19219)
*Zi Liang,Liantong Yu,Shiyu Zhang,Qingqing Ye,Haibo Hu*

Main category: cs.CL

TL;DR: The paper identifies overestimation issues in LLM evaluation due to benchmark contamination and proposes ArxivRoll, a dynamic, private evaluation framework using latest research articles and Rugged Scores to ensure fairer, more transparent assessment.


<details>
  <summary>Details</summary>
Motivation: To address the overestimation of LLM performance caused by benchmark contamination and ensure fair, reproducible evaluations.

Method: Introducing ArxivRoll, which includes SCP for private test case generation and Rugged Scores for contamination assessment, using recent ArXiv articles for periodic, one-time evaluations.

Result: ArxivRoll creates high-quality, dynamic benchmarks, enabling systematic and fair evaluation of LLMs, revealing potential overestimations in current models.

Conclusion: ArxivRoll effectively mitigates overestimation issues, providing a reproducible, transparent framework for LLM evaluation.

Abstract: Overestimation in evaluating large language models (LLMs) has become an
increasing concern. Due to the contamination of public benchmarks or imbalanced
model training, LLMs may achieve unreal evaluation results on public
benchmarks, either intentionally or unintentionally, which leads to unfair
comparisons among LLMs and undermines their realistic capability assessments.
Existing benchmarks attempt to address these issues by keeping test cases
permanently secret, mitigating contamination through human evaluation, or
repeatedly collecting and constructing new samples. However, these approaches
fail to ensure reproducibility, transparency, and high efficiency
simultaneously. Moreover, the extent of overestimation in current LLMs remains
unquantified. To address these issues, we propose ArxivRoll, a dynamic
evaluation framework inspired by one-time pad encryption in cryptography.
ArxivRoll comprises two key components: \emph{i) SCP (Sequencing, Cloze, and
Prediction)}, an automated generator for private test cases, and \emph{ii)
Rugged Scores (RS)}, metrics that measure the proportion of public benchmark
contamination and training bias. Leveraging SCP, ArxivRoll constructs a new
benchmark every six months using recent articles from ArXiv and employs them
for one-time evaluations of LLM performance. Extensive experiments demonstrate
the high quality of our benchmark, and we provide a systematic evaluation of
current LLMs. The source code is available at
https://github.com/liangzid/ArxivRoll/.

</details>


### [25] [Jailbreaking Large Language Diffusion Models: Revealing Hidden Safety Flaws in Diffusion-Based Text Generation](https://arxiv.org/abs/2507.19227)
*Yuanhe Zhang,Fangzhou Xie,Zhenhong Zhou,Zherui Li,Hao Chen,Kun Wang,Yufei Guo*

Main category: cs.CL

TL;DR: The paper exposes safety vulnerabilities in Large Language Diffusion Models (LLDMs) using a novel jailbreak method called PAD, which successfully causes harmful outputs and raises concerns about uncontrolled misuse.


<details>
  <summary>Details</summary>
Motivation: To investigate safety robustness and security vulnerabilities of LLDMs, especially in comparison to LLMs.

Method: Proposes PAD, a parallel decoding jailbreak with Multi-Point Attention Attack, to trigger harmful outputs in LLDMs.

Result: PAD achieves a 97% success rate in jailbreaking LLDMs; LLDMs produce harmful content twice as fast as comparable LLMs, highlighting increased risks.

Conclusion: LLDMs are vulnerable to jailbreak attacks, and their rapid harmful output generation poses significant safety concerns, requiring careful security measures.

Abstract: Large Language Diffusion Models (LLDMs) exhibit comparable performance to
LLMs while offering distinct advantages in inference speed and mathematical
reasoning tasks.The precise and rapid generation capabilities of LLDMs amplify
concerns of harmful generations, while existing jailbreak methodologies
designed for Large Language Models (LLMs) prove limited effectiveness against
LLDMs and fail to expose safety vulnerabilities.Successful defense cannot
definitively resolve harmful generation concerns, as it remains unclear whether
LLDMs possess safety robustness or existing attacks are incompatible with
diffusion-based architectures.To address this, we first reveal the
vulnerability of LLDMs to jailbreak and demonstrate that attack failure in
LLDMs stems from fundamental architectural differences.We present a PArallel
Decoding jailbreak (PAD) for diffusion-based language models. PAD introduces
Multi-Point Attention Attack, which guides parallel generative processes toward
harmful outputs that inspired by affirmative response patterns in LLMs.
Experimental evaluations across four LLDMs demonstrate that PAD achieves
jailbreak attack success rates by 97%, revealing significant safety
vulnerabilities. Furthermore, compared to autoregressive LLMs of the same size,
LLDMs increase the harmful generation speed by 2x, significantly highlighting
risks of uncontrolled misuse.Through comprehensive analysis, we provide an
investigation into LLDM architecture, offering critical insights for the secure
deployment of diffusion-based language models.

</details>


### [26] [Smooth Reading: Bridging the Gap of Recurrent LLM to Self-Attention LLM on Long-Context Tasks](https://arxiv.org/abs/2507.19353)
*Kai Liu,Zhan Su,Peijie Dong,Fengran Mo,Jianfei Gao,ShaoTing Zhang,Kai Chen*

Main category: cs.CL

TL;DR: Smooth Reading significantly improves Recurrent LLMs' performance on long-context tasks, narrowing the gap with Self-Attention LLMs while maintaining efficiency.


<details>
  <summary>Details</summary>
Motivation: Recurrent LLMs are more computationally efficient but underperform on long-context tasks compared to Self-Attention LLMs. The goal is to enhance their effectiveness.

Method: Introducing Smooth Reading, a chunk-wise inference approach that processes context in segments and iteratively summarizes information, inspired by human reading strategies.

Result: The method improves Recurrent LLMs' performance on long-context tasks, reducing the performance gap from -5.68% to +3.61% relative to Self-Attention LLMs, and increases efficiency (training 3x faster, inference 2x faster).

Conclusion: Smooth Reading bridges the performance gap between Recurrent and Self-Attention LLMs on long-context tasks while preserving efficiency, representing a novel contribution in this research area.

Abstract: Recently, recurrent large language models (Recurrent LLMs) with linear
computational complexity have re-emerged as efficient alternatives to
self-attention-based LLMs (Self-Attention LLMs), which have quadratic
complexity. However, Recurrent LLMs often underperform on long-context tasks
due to their limited fixed-size memory. Previous research has primarily focused
on enhancing the memory capacity of Recurrent LLMs through architectural
innovations, but these approaches have not yet enabled Recurrent LLMs to match
the performance of Self-Attention LLMs on long-context tasks. We argue that
this limitation arises because processing the entire context at once is not
well-suited for Recurrent LLMs. In this paper, we propose Smooth Reading, a
chunk-wise inference method inspired by human reading strategies. Smooth
Reading processes context in chunks and iteratively summarizes the contextual
information, thereby reducing memory demands and making the approach more
compatible with Recurrent LLMs. Our experimental results show that this method
substantially narrows the performance gap between Recurrent and Self-Attention
LLMs on long-context tasks, while preserving the efficiency advantages of
Recurrent LLMs. Our Smooth Reading boosts SWA-3B-4k (a Recurrent LLM) from
5.68% lower to 3.61% higher performance than Self-Attention LLMs on LongBench.
Besides, our method maintains the high efficiency, training 3x faster and
inferring 2x faster at 64k context compared to Self-Attention LLMs. To our
knowledge, this is the first work to achieve comparable performance using
Recurrent LLMs compared with Self-Attention LLMs on long-context tasks. We hope
our method will inspire future research in this area. To facilitate further
progress, we will release code and dataset.

</details>


### [27] [Identifying Fine-grained Forms of Populism in Political Discourse: A Case Study on Donald Trump's Presidential Campaigns](https://arxiv.org/abs/2507.19303)
*Ilias Chalkidis,Stephanie Brandl,Paris Aslanidis*

Main category: cs.CL

TL;DR: The paper investigates the ability of Large Language Models to identify and classify populist discourse, highlighting their limitations and the effectiveness of fine-tuning, with applications to political speeches.


<details>
  <summary>Details</summary>
Motivation: To explore the capacity of LLMs to understand complex social science concepts like populism, which remain underexplored.

Method: Curating new datasets on populist discourse, evaluating various pre-trained and instruction-tuned models across different prompting paradigms, and fine-tuning models for improved performance.

Result: Fine-tuned RoBERTa significantly outperforms instruction-tuned LLMs in detecting populism; instruction-tuned models are more robust on out-of-domain political speech data.

Conclusion: While LLMs show promise, they have limitations in capturing nuanced social concepts, but fine-tuning can enhance their effectiveness and robustness.

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
a wide range of instruction-following tasks, yet their grasp of nuanced social
science concepts remains underexplored. This paper examines whether LLMs can
identify and classify fine-grained forms of populism, a complex and contested
concept in both academic and media debates. To this end, we curate and release
novel datasets specifically designed to capture populist discourse. We evaluate
a range of pre-trained (large) language models, both open-weight and
proprietary, across multiple prompting paradigms. Our analysis reveals notable
variation in performance, highlighting the limitations of LLMs in detecting
populist discourse. We find that a fine-tuned RoBERTa classifier vastly
outperforms all new-era instruction-tuned LLMs, unless fine-tuned.
Additionally, we apply our best-performing model to analyze campaign speeches
by Donald Trump, extracting valuable insights into his strategic use of
populist rhetoric. Finally, we assess the generalizability of these models by
benchmarking them on campaign speeches by European politicians, offering a lens
into cross-context transferability in political discourse analysis. In this
setting, we find that instruction-tuned LLMs exhibit greater robustness on
out-of-domain data.

</details>


### [28] [SpeechIQ: Speech Intelligence Quotient Across Cognitive Levels in Voice Understanding Large Language Models](https://arxiv.org/abs/2507.19361)
*Zhen Wan,Chao-Han Huck Yang,Yahan Yu,Jinchuan Tian,Sheng Li,Ke Hu,Zhehuai Chen,Shinji Watanabe,Fei Cheng,Chenhui Chu,Sadao Kurohashi*

Main category: cs.CL

TL;DR: SIQ is a new evaluation framework inspired by cognitive levels, designed to assess voice understanding in large language models, beyond traditional metrics.


<details>
  <summary>Details</summary>
Motivation: To develop a comprehensive method for evaluating voice understanding capabilities in LLMs that captures cognitive processes.

Method: Introducing SIQ, which assesses models across three cognitive levels inspired by Bloom's Taxonomy, using metrics like WER, interpretative similarity, and QA accuracy.

Result: SIQ effectively measures voice understanding, compares models, identifies benchmark errors, and detects hallucinations, providing new insights into multi-modal model challenges.

Conclusion: SIQ offers a pioneering cognitive-inspired benchmark for voice understanding, exposing gaps in current evaluations and highlighting challenges in multi-modal training.

Abstract: We introduce Speech-based Intelligence Quotient (SIQ) as a new form of human
cognition-inspired evaluation pipeline for voice understanding large language
models, LLM Voice, designed to assess their voice understanding ability. Moving
beyond popular voice understanding metrics such as word error rate (WER), SIQ
examines LLM Voice across three cognitive levels motivated by Bloom's Taxonomy:
(1) Remembering (i.e., WER for verbatim accuracy); (2) Understanding (i.e.,
similarity of LLM's interpretations); and (3) Application (i.e., QA accuracy
for simulating downstream tasks). We demonstrate that SIQ not only quantifies
voice understanding abilities but also provides unified comparisons between
cascaded methods (e.g., ASR LLM) and end-to-end models, identifies annotation
errors in existing benchmarks, and detects hallucinations in LLM Voice. Our
framework represents a first-of-its-kind intelligence examination that bridges
cognitive principles with voice-oriented benchmarks, while exposing overlooked
challenges in multi-modal training.

</details>


### [29] [AutoPCR: Automated Phenotype Concept Recognition by Prompting](https://arxiv.org/abs/2507.19315)
*Yicheng Tao,Yuanhao Huang,Jie Liu*

Main category: cs.CL

TL;DR: AutoPCR is a prompt-based phenotype recognition method that generalizes well across datasets without ontology-specific training.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of existing phenotype concept recognition methods that require ontology-specific training and struggle with diverse texts and evolving biomedical terminology.

Method: AutoPCR combines rule-based and neural tagging for entity extraction, SapBERT for candidate retrieval, and large language models for entity linking, all without needing specialized training.

Result: AutoPCR outperforms existing state-of-the-art methods across multiple benchmarks, showing robustness and better generalization, including to new ontologies.

Conclusion: AutoPCR provides a flexible, effective, and ontology-agnostic approach for phenotype concept recognition in biomedical texts.

Abstract: Phenotype concept recognition (CR) is a fundamental task in biomedical text
mining, enabling applications such as clinical diagnostics and knowledge graph
construction. However, existing methods often require ontology-specific
training and struggle to generalize across diverse text types and evolving
biomedical terminology. We present AutoPCR, a prompt-based phenotype CR method
that does not require ontology-specific training. AutoPCR performs CR in three
stages: entity extraction using a hybrid of rule-based and neural tagging
strategies, candidate retrieval via SapBERT, and entity linking through
prompting a large language model. Experiments on four benchmark datasets show
that AutoPCR achieves the best average and most robust performance across both
mention-level and document-level evaluations, surpassing prior state-of-the-art
methods. Further ablation and transfer studies demonstrate its inductive
capability and generalizability to new ontologies.

</details>


### [30] [Data Augmentation for Spoken Grammatical Error Correction](https://arxiv.org/abs/2507.19374)
*Penny Karanasou,Mengjie Qian,Stefano Bannò,Mark J. F. Gales,Kate M. Knill*

Main category: cs.CL

TL;DR: This paper introduces an automated method to generate audio-text pairs with grammatical errors and disfluencies for Spoken GEC, creating augmented datasets to improve error correction without affecting language assessment scores.


<details>
  <summary>Details</summary>
Motivation: Address the scarcity of high-quality annotated spoken datasets for Spoken GEC and enhance dataset diversity.

Method: Automated generation of audio-text pairs with errors and disfluencies, along with objective metrics for quality evaluation.

Result: Proposed dataset augmentation enriches the original corpus for both written and spoken GEC tasks, validated on the S&I Corpus.

Conclusion: The augmented dataset maintains original characteristics and provides new error types, benefiting error correction research.

Abstract: While there exist strong benchmark datasets for grammatical error correction
(GEC), high-quality annotated spoken datasets for Spoken GEC (SGEC) are still
under-resourced. In this paper, we propose a fully automated method to generate
audio-text pairs with grammatical errors and disfluencies. Moreover, we propose
a series of objective metrics that can be used to evaluate the generated data
and choose the more suitable dataset for SGEC. The goal is to generate an
augmented dataset that maintains the textual and acoustic characteristics of
the original data while providing new types of errors. This augmented dataset
should augment and enrich the original corpus without altering the language
assessment scores of the second language (L2) learners. We evaluate the use of
the augmented corpus both for written GEC (the text part) and for SGEC (the
audio-text pairs). Our experiments are conducted on the S\&I Corpus, the first
publicly available speech dataset with grammar error annotations.

</details>


### [31] [GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning](https://arxiv.org/abs/2507.19457)
*Lakshya A Agrawal,Shangyin Tan,Dilara Soylu,Noah Ziems,Rishi Khare,Krista Opsahl-Ong,Arnav Singhvi,Herumb Shandilya,Michael J Ryan,Meng Jiang,Christopher Potts,Koushik Sen,Alexandros G. Dimakis,Ion Stoica,Dan Klein,Matei Zaharia,Omar Khattab*

Main category: cs.CL

TL;DR: GEPA, a prompt optimizer leveraging natural language reflection, significantly outperforms traditional RL methods like GRPO, achieving higher quality with fewer rollouts.


<details>
  <summary>Details</summary>
Motivation: To improve the efficiency and effectiveness of adapting large language models (LLMs) to downstream tasks beyond traditional reinforcement learning methods.

Method: Introducing GEPA, which uses natural language reflection on system trajectories to diagnose, update prompts, and learn from a Pareto frontier of attempts.

Result: GEPA outperforms GRPO by 10-20% while using up to 35x fewer rollouts and surpasses MIPROv2 by over 10%, with promising applications in code optimization.

Conclusion: Leveraging natural language reflection within GEPA enables more sample-efficient and higher-quality adaptation of LLMs compared to existing methods.

Abstract: Large language models (LLMs) are increasingly adapted to downstream tasks via
reinforcement learning (RL) methods like Group Relative Policy Optimization
(GRPO), which often require thousands of rollouts to learn new tasks. We argue
that the interpretable nature of language can often provide a much richer
learning medium for LLMs, compared with policy gradients derived from sparse,
scalar rewards. To test this, we introduce GEPA (Genetic-Pareto), a prompt
optimizer that thoroughly incorporates natural language reflection to learn
high-level rules from trial and error. Given any AI system containing one or
more LLM prompts, GEPA samples system-level trajectories (e.g., reasoning, tool
calls, and tool outputs) and reflects on them in natural language to diagnose
problems, propose and test prompt updates, and combine complementary lessons
from the Pareto frontier of its own attempts. As a result of GEPA's design, it
can often turn even just a few rollouts into a large quality gain. Across four
tasks, GEPA outperforms GRPO by 10% on average and by up to 20%, while using up
to 35x fewer rollouts. GEPA also outperforms the leading prompt optimizer,
MIPROv2, by over 10% across two LLMs, and demonstrates promising results as an
inference-time search strategy for code optimization.

</details>


### [32] [Enhancing Speech Emotion Recognition Leveraging Aligning Timestamps of ASR Transcripts and Speaker Diarization](https://arxiv.org/abs/2507.19356)
*Hsuan-Yu Wang,Pei-Ying Lee,Berlin Chen*

Main category: cs.CL

TL;DR: Incorporating timestamp-based alignment between ASR transcripts and speaker diarization improves speech emotion recognition accuracy by ensuring better multimodal synchronization.


<details>
  <summary>Details</summary>
Motivation: The study aims to address the challenge of modality misalignment in multimodal speech emotion recognition systems, which hampers their reliability, especially in conversational contexts.

Method: The authors develop an alignment pipeline using pre-trained ASR and SD models to synchronize timestamps, and combine textual and audio embeddings with cross-attention and gating for multimodal fusion, evaluated on IEMOCAP.

Result: Precise timestamp alignment enhances SER accuracy, outperforming non-synchronized baseline methods.

Conclusion: Temporal alignment is crucial for improving multimodal emotion recognition, leading to more robust and accurate systems.

Abstract: In this paper, we investigate the impact of incorporating timestamp-based
alignment between Automatic Speech Recognition (ASR) transcripts and Speaker
Diarization (SD) outputs on Speech Emotion Recognition (SER) accuracy.
Misalignment between these two modalities often reduces the reliability of
multimodal emotion recognition systems, particularly in conversational
contexts. To address this issue, we introduce an alignment pipeline utilizing
pre-trained ASR and speaker diarization models, systematically synchronizing
timestamps to generate accurately labeled speaker segments. Our multimodal
approach combines textual embeddings extracted via RoBERTa with audio
embeddings from Wav2Vec, leveraging cross-attention fusion enhanced by a gating
mechanism. Experimental evaluations on the IEMOCAP benchmark dataset
demonstrate that precise timestamp alignment improves SER accuracy,
outperforming baseline methods that lack synchronization. The results highlight
the critical importance of temporal alignment, demonstrating its effectiveness
in enhancing overall emotion recognition accuracy and providing a foundation
for robust multimodal emotion analysis.

</details>


### [33] [Detection of Adverse Drug Events in Dutch clinical free text documents using Transformer Models: benchmark study](https://arxiv.org/abs/2507.19396)
*Rachel M. Murphy,Nishant Mishra,Nicolette F. de Keizer,Dave A. Dongelmans,Kitty J. Jager,Ameen Abu-Hanna,Joanna E. Klopotowska,Iacer Calixto*

Main category: cs.CL

TL;DR: This study benchmarks transformer models for adverse drug event detection in Dutch clinical texts, showing MedRoBERTa.nl performs best with reliable detection rates.


<details>
  <summary>Details</summary>
Motivation: To establish a performance benchmark for ADE detection in Dutch clinical free text using advanced NLP models.

Method: Trained and evaluated several transformer-based (Dutch/multilingual) and LSTM models on annotated ICU and hospital discharge notes, measuring NER and RC tasks with internal and external validations.

Result: MedRoBERTa.nl outperformed other models with macro-F1 of 0.63 (gold standard) and 0.62 (predicted entities); achieved 67-74% recall externally.

Conclusion: Transformer models, especially MedRoBERTa.nl, are effective for ADE detection in Dutch clinical texts, emphasizing the importance of appropriate metrics for clinical NLP evaluation.

Abstract: In this study, we set a benchmark for adverse drug event (ADE) detection in
Dutch clinical free text documents using several transformer models, clinical
scenarios and fit-for-purpose performance measures. We trained a Bidirectional
Long Short-Term Memory (Bi-LSTM) model and four transformer-based Dutch and/or
multilingual encoder models (BERTje, RobBERT, MedRoBERTa.nl, and NuNER) for the
tasks of named entity recognition (NER) and relation classification (RC) using
102 richly annotated Dutch ICU clinical progress notes. Anonymized free text
clinical progress notes of patients admitted to intensive care unit (ICU) of
one academic hospital and discharge letters of patients admitted to Internal
Medicine wards of two non-academic hospitals were reused. We evaluated our ADE
RC models internally using gold standard (two-step task) and predicted entities
(end-to-end task). In addition, all models were externally validated on
detecting ADEs at the document level. We report both micro- and macro-averaged
F1 scores, given the imbalance of ADEs in the datasets. Although differences
for the ADE RC task between the models were small, MedRoBERTa.nl was the best
performing model with macro-averaged F1 score of 0.63 using gold standard and
0.62 using predicted entities. The MedRoBERTa.nl models also performed the best
in our external validation and achieved recall of between 0.67 to 0.74 using
predicted entities, meaning between 67 to 74% of discharge letters with ADEs
were detected. Our benchmark study presents a robust and clinically meaningful
approach for evaluating language models for ADE detection in clinical free text
documents. Our study highlights the need to use appropriate performance
measures fit for the task of ADE detection in clinical free-text documents and
envisioned future clinical use.

</details>


### [34] [Towards Domain Specification of Embedding Models in Medicine](https://arxiv.org/abs/2507.19407)
*Mohammad Khodadad,Ali Shiraee,Mahdi Astaraki,Hamidreza Mahyar*

Main category: cs.CL

TL;DR: A new medical text embedding model, MEDTE, improves performance and robustness across diverse healthcare tasks by leveraging extensive fine-tuning and a comprehensive evaluation suite.


<details>
  <summary>Details</summary>
Motivation: Current medical text embeddings are limited by narrow data sources and inadequate evaluation methods, hindering their effectiveness in real-world applications.

Method: Fine-tuning MEDTE on diverse medical corpora with self-supervised contrastive learning and evaluating it with a comprehensive benchmark of 51 tasks across various metrics.

Result: MEDTE produces more robust and accurate embeddings that outperform existing models across multiple clinical and biomedical tasks.

Conclusion: The combined approach of extensive fine-tuning and comprehensive benchmarking enhances the quality and applicability of medical text embeddings.

Abstract: Medical text embedding models are foundational to a wide array of healthcare
applications, ranging from clinical decision support and biomedical information
retrieval to medical question answering, yet they remain hampered by two
critical shortcomings. First, most models are trained on a narrow slice of
medical and biological data, beside not being up to date in terms of
methodology, making them ill suited to capture the diversity of terminology and
semantics encountered in practice. Second, existing evaluations are often
inadequate: even widely used benchmarks fail to generalize across the full
spectrum of real world medical tasks.
  To address these gaps, we leverage MEDTE, a GTE model extensively fine-tuned
on diverse medical corpora through self-supervised contrastive learning across
multiple data sources, to deliver robust medical text embeddings.
  Alongside this model, we propose a comprehensive benchmark suite of 51 tasks
spanning classification, clustering, pair classification, and retrieval modeled
on the Massive Text Embedding Benchmark (MTEB) but tailored to the nuances of
medical text. Our results demonstrate that this combined approach not only
establishes a robust evaluation framework but also yields embeddings that
consistently outperform state of the art alternatives in different tasks.

</details>


### [35] [TokenSmith: Streamlining Data Editing, Search, and Inspection for Large-Scale Language Model Training and Interpretability](https://arxiv.org/abs/2507.19419)
*Mohammad Aflah Khan,Ameya Godbole,Johnny Tian-Zheng Wei,Ryan Wang,James Flemings,Krishna Gummadi,Willie Neiswanger,Robin Jia*

Main category: cs.CL

TL;DR: TokenSmith is an open-source tool for dataset analysis and editing in large language model pretraining, improving workflow accessibility and flexibility.


<details>
  <summary>Details</summary>
Motivation: To address the cumbersome and fragmented workflows in analyzing and editing datasets used during model pretraining.

Method: Developed an interactive, modular tool with features for searching, viewing, exporting, and editing datasets in existing frameworks.

Result: Provides a user-friendly, behind-the-scenes, plug-and-play solution that simplifies dataset management without altering training code.

Conclusion: TokenSmith democratizes dataset tooling in large language model training, enhancing reproducibility and experimentation.

Abstract: Understanding the relationship between training data and model behavior
during pretraining is crucial, but existing workflows make this process
cumbersome, fragmented, and often inaccessible to researchers. We present
TokenSmith, an open-source library for interactive editing, inspection, and
analysis of datasets used in Megatron-style pretraining frameworks such as
GPT-NeoX, Megatron, and NVIDIA NeMo. TokenSmith supports a wide range of
operations including searching, viewing, ingesting, exporting, inspecting, and
sampling data, all accessible through a simple user interface and a modular
backend. It also enables structured editing of pretraining data without
requiring changes to training code, simplifying dataset debugging, validation,
and experimentation.
  TokenSmith is designed as a plug and play addition to existing large language
model pretraining workflows, thereby democratizing access to production-grade
dataset tooling. TokenSmith is hosted on GitHub1, with accompanying
documentation and tutorials. A demonstration video is also available on
YouTube.

</details>


### [36] [Conversations Gone Awry, But Then? Evaluating Conversational Forecasting Models](https://arxiv.org/abs/2507.19470)
*Son Quoc Tran,Tushaar Gangavarapu,Nicholas Chernogor,Jonathan P. Chang,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: Introduction of a new benchmark and evaluation framework for predicting conversation derailment, enabling comparison of models and assessing their adaptability over time.


<details>
  <summary>Details</summary>
Motivation: To improve automated systems' ability to anticipate and assist in human conversations by accurately predicting when a dialogue might go awry.

Method: Developing a uniform evaluation framework and benchmark for the Conversations Gone Awry task, including a new metric to assess model performance over the conversation timeline.

Result: Established a standardized way to compare different models on the CGA task, highlighting progress and enabling more reliable assessments aligned with recent advancements in language modeling.

Conclusion: The framework advances the evaluation of predictive conversation models, facilitating further research and development in proactive conversational AI.

Abstract: We often rely on our intuition to anticipate the direction of a conversation.
Endowing automated systems with similar foresight can enable them to assist
human-human interactions. Recent work on developing models with this predictive
capacity has focused on the Conversations Gone Awry (CGA) task: forecasting
whether an ongoing conversation will derail. In this work, we revisit this task
and introduce the first uniform evaluation framework, creating a benchmark that
enables direct and reliable comparisons between different architectures. This
allows us to present an up-to-date overview of the current progress in CGA
models, in light of recent advancements in language modeling. Our framework
also introduces a novel metric that captures a model's ability to revise its
forecast as the conversation progresses.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [37] [ApproxJoin: Approximate Matching for Efficient Verification in Fuzzy Set Similarity Join](https://arxiv.org/abs/2507.18891)
*Michael Mandulak,S M Ferdous,Sayan Ghosh,Mahantesh Halappanavar,George Slota*

Main category: cs.DB

TL;DR: ApproxJoin improves fuzzy set similarity join verification by using approximate maximum weight matching algorithms, achieving 2-19x faster performance with 99% recall.


<details>
  <summary>Details</summary>
Motivation: To address high computational costs in fuzzy set similarity join verification, typically using the Hungarian algorithm.

Method: Applying and testing three approximate maximum weight matching algorithms in the verification step.

Result: Significant performance improvements of 2-19 times over existing methods with high accuracy.

Conclusion: Approximate matching methods can effectively substitute exact methods in verification, offering substantial speedups in fuzzy set similarity joins.

Abstract: The set similarity join problem is a fundamental problem in data processing
and discovery, relying on exact similarity measures between sets. In the
presence of alterations, such as misspellings on string data, the fuzzy set
similarity join problem instead approximately matches pairs of elements based
on the maximum weighted matching of the bipartite graph representation of sets.
State-of-the-art methods within this domain improve performance through
efficient filtering methods within the filter-verify framework, primarily to
offset high verification costs induced by the usage of the Hungarian algorithm
- an optimal matching method. Instead, we directly target the verification
process to assess the efficacy of more efficient matching methods within
candidate pair pruning.
  We present ApproxJoin, the first work of its kind in applying approximate
maximum weight matching algorithms for computationally expensive fuzzy set
similarity join verification. We comprehensively test the performance of three
approximate matching methods: the Greedy, Locally Dominant and Paz Schwartzman
methods, and compare with the state-of-the-art approach using exact matching.
Our experimental results show that ApproxJoin yields performance improvements
of 2-19x the state-of-the-art with high accuracy (99% recall).

</details>


### [38] [Big Data Energy Systems: A Survey of Practices and Associated Challenges](https://arxiv.org/abs/2507.19154)
*Lunodzo J. Mwinuka,Massimo Cafaro,Lucas Pereira,Hugo Morais*

Main category: cs.DB

TL;DR: A review of big data management challenges and emerging technologies in energy systems, emphasizing scalability, regulation, and innovative architectures.


<details>
  <summary>Details</summary>
Motivation: To address the increasing data volumes in energy systems and the limitations of current management solutions.

Method: Review of research trends, practices, and emerging technologies including data spaces, architectures, P2P management, and blockchain.

Result: Identification of current limitations and potential of new technologies for better data sharing and regulatory compliance.

Conclusion: Emerging technologies can significantly improve energy data management, but challenges remain regarding scalability and regulation.

Abstract: Energy systems generate vast amounts of data in extremely short time
intervals, creating challenges for efficient data management. Traditional data
management methods often struggle with scalability and accessibility, limiting
their usefulness. More advanced solutions, such as NoSQL databases and
cloud-based platforms, have been adopted to address these issues. Still, even
these advanced solutions can encounter bottlenecks, which can impact the
efficiency of data storage, retrieval, and analysis. This review paper explores
the research trends in big data management for energy systems, highlighting the
practices, opportunities and challenges. Also, the data regulatory demands are
highlighted using chosen reference architectures. The review, in particular,
explores the limitations of current storage and data integration solutions and
examines how new technologies are applied to the energy sector. Novel insights
into emerging technologies, including data spaces, various data management
architectures, peer-to-peer data management, and blockchains, are provided,
along with practical recommendations for achieving enhanced data sharing and
regulatory compliance.

</details>


### [39] [DBMS-LLM Integration Strategies in Industrial and Business Applications: Current Status and Future Challenges](https://arxiv.org/abs/2507.19254)
*Zhengtong Yan,Gongsheng Yuan,Qingsong Guo,Jiaheng Lu*

Main category: cs.DB

TL;DR: This paper surveys recent developments in integrating Database Management Systems (DBMSs) with Large Language Models (LLMs), categorizing five architectural patterns and highlighting future challenges for scalable and efficient integration.


<details>
  <summary>Details</summary>
Motivation: The motivation is to understand how to effectively combine traditional data management with advanced language reasoning to support modern AI-driven applications.

Method: The paper reviews recent developments, categorizes architectural patterns based on design principles, strengths, and trade-offs, and discusses key open challenges.

Result: The survey provides a systematic understanding of current integration architectures and identifies critical unresolved issues for future research.

Conclusion: Achieving scalable and efficient integration of DBMSs and LLMs is vital for advancing intelligent applications, and several open challenges must be addressed.

Abstract: Modern enterprises are increasingly driven by the DATA+AI paradigm, in which
Database Management Systems (DBMSs) and Large Language Models (LLMs) have
become two foundational infrastructures powering a wide range of industrial and
business applications, such as enterprise analytics, intelligent customer
service, and data-driven decision-making. The efficient integration of DBMSs
and LLMs within a unified system offers significant opportunities but also
introduces new technical challenges. This paper surveys recent developments in
DBMS+LLM integration and identifies key future challenges. Specifically, we
categorize five representative architectural patterns based on their core
design principles, strengths, and trade-offs. Based on this analysis, we
further highlight several critical open challenges. We aim to provide a
systematic understanding of the current integration landscape and to outline
the unresolved issues that must be addressed to achieve scalable and efficient
integration of traditional data management and advanced language reasoning in
future intelligent applications.

</details>


### [40] [Properties for Paths in Graph Databases](https://arxiv.org/abs/2507.19329)
*Fernando Orejas,Elvira Pino,Renzo Angles,E. Pasarella,Nikos Milonakis*

Main category: cs.DB

TL;DR: The paper introduces a formalism for defining and filtering path properties in graph databases, improving query expressiveness and efficiency.


<details>
  <summary>Details</summary>
Motivation: To enhance graph database query capabilities by incorporating path properties such as length and cost, enabling more refined searches.

Method: Develops an operational semantics for a query language with path property constructs, proves its soundness and completeness, analyzes its expressive power, and evaluates performance with a prototype implementation.

Result: The formalism is sound, more expressive than register automata, and queries using path properties outperform standard queries in empirical tests.

Conclusion: The new formalism effectively improves query filtering and can be efficiently implemented, advancing graph database analysis.

Abstract: This paper presents a formalism for defining properties of paths in graph
databases, which can be used to restrict the number of solutions to
navigational queries. In particular, our formalism allows us to define
quantitative properties such as length or accumulated cost, which can be used
as query filters. Furthermore, it enables the identification and removal of
paths that may be considered ill-formed.
  The new formalism is defined in terms of an operational semantics for the
query language that incorporates these new constructs, demonstrating its
soundness and completeness by proving its compatibility with a simple logical
semantics. We also analyze its expressive power, showing that path properties
are more expressive than register automata. Finally, after discussing some
complexity issues related to this new approach, we present an empirical
analysis carried out using our prototype implementation of the graph database
that serves as a running example throughout the paper. The results show that
queries using path properties as filters outperform standard queries that do
not use them.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [41] [Initial Steps in Integrating Large Reasoning and Action Models for Service Composition](https://arxiv.org/abs/2507.18775)
*Ilche Georgievski,Marco Aiello*

Main category: cs.AI

TL;DR: Integrating Large Reasoning Models and Large Action Models can improve automated service composition by combining reasoning and execution abilities.


<details>
  <summary>Details</summary>
Motivation: Enhance service composition in software systems by leveraging the complementary strengths of LRMs and LAMs.

Method: Proposing an integrated architectural framework combining LRMs for reasoning and LAMs for action execution.

Result: A conceptual framework demonstrating how integration can enable more autonomous and intelligent service composition.

Conclusion: Integrating LRMs and LAMs offers a promising pathway to fully automate and simplify service composition based on natural language intents.

Abstract: Service composition remains a central challenge in building adaptive and
intelligent software systems, often constrained by limited reasoning
capabilities or brittle execution mechanisms. This paper explores the
integration of two emerging paradigms enabled by large language models: Large
Reasoning Models (LRMs) and Large Action Models (LAMs). We argue that LRMs
address the challenges of semantic reasoning and ecosystem complexity while
LAMs excel in dynamic action execution and system interoperability. However,
each paradigm has complementary limitations - LRMs lack grounded action
capabilities, and LAMs often struggle with deep reasoning. We propose an
integrated LRM-LAM architectural framework as a promising direction for
advancing automated service composition. Such a system can reason about service
requirements and constraints while dynamically executing workflows, thus
bridging the gap between intention and execution. This integration has the
potential to transform service composition into a fully automated,
user-friendly process driven by high-level natural language intent.

</details>


### [42] [Simulation-Driven Reinforcement Learning in Queuing Network Routing Optimization](https://arxiv.org/abs/2507.18795)
*Fatima Al-Ani,Molly Wang,Jevon Charles,Aaron Ong,Joshua Forday,Vinayak Modi*

Main category: cs.AI

TL;DR: This paper introduces a robust simulation-driven RL framework using DDPG and Dyna-style planning for optimizing routing in complex queueing systems, demonstrating strong performance and scalability.


<details>
  <summary>Details</summary>
Motivation: Traditional queueing methods are insufficient in dynamic, uncertain environments, necessitating advanced adaptive solutions.

Method: Development of a flexible simulation environment combined with an enhanced Dyna-DDPG algorithm employing separate predictive models for stability and efficiency.

Result: The framework effectively learns routing policies that are robust to disruptions and scalable to larger networks, verified through comprehensive experiments.

Conclusion: The proposed RL framework offers a practical, maintainable solution for complex queueing systems, suitable for real-world deployment.

Abstract: This study focuses on the development of a simulation-driven reinforcement
learning (RL) framework for optimizing routing decisions in complex queueing
network systems, with a particular emphasis on manufacturing and communication
applications. Recognizing the limitations of traditional queueing methods,
which often struggle with dynamic, uncertain environments, we propose a robust
RL approach leveraging Deep Deterministic Policy Gradient (DDPG) combined with
Dyna-style planning (Dyna-DDPG). The framework includes a flexible and
configurable simulation environment capable of modeling diverse queueing
scenarios, disruptions, and unpredictable conditions. Our enhanced Dyna-DDPG
implementation incorporates separate predictive models for next-state
transitions and rewards, significantly improving stability and sample
efficiency. Comprehensive experiments and rigorous evaluations demonstrate the
framework's capability to rapidly learn effective routing policies that
maintain robust performance under disruptions and scale effectively to larger
network sizes. Additionally, we highlight strong software engineering practices
employed to ensure reproducibility and maintainability of the framework,
enabling practical deployment in real-world scenarios.

</details>


### [43] [A Neuroscience-Inspired Dual-Process Model of Compositional Generalization](https://arxiv.org/abs/2507.18868)
*Alex Noviello,Claas Beger,Jacob Groner,Kevin Ellis,Weinan Sun*

Main category: cs.AI

TL;DR: MIRAGE is a framework inspired by brain function that enhances AI's ability to generalize compositionally, achieving over 99% accuracy on benchmark tasks with a small parameter count.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of systematic compositional generalization in AI, inspired by human cognition involving hippocampus and prefrontal cortex interactions.

Method: MIRAGE combines a meta-trained Transformer for decomposition with a Schema Engine for schema extraction, ranking, and application, mimicking brain processes.

Result: Achieved over 99% accuracy on the SCAN benchmark, demonstrating effective systematic compositional generalization with minimal parameters.

Conclusion: Explicit schematic structures and iterative refinement are crucial for MIRAGE's success in compositional generalization.

Abstract: Systematic compositional generalization - constructing and understanding
novel combinations of known building blocks - remains a core challenge for AI
systems. Human cognition achieves this flexibility via the interplay of the
hippocampus (HPC) and prefrontal cortex (PFC): the hippocampus rapidly encodes
episodes, and the prefrontal cortex consolidates them into reusable schemas for
reasoning. Drawing on these insights, we present MIRAGE (Meta-Inference with
Rules and Abstractions from Generalized Experience), a framework that achieves
systematic generalization on compositional tasks. MIRAGE has two interacting
modules mirroring the brain's deliberative HPC-PFC loop and intuitive
neocortical pattern recognition. (1) The meta-trained Transformer Neural
Decomposer, paralleling neocortical "System 1" computation, is trained on a
task-agnostic stream of randomly sampled compositional grammars and applies one
decomposition step per pass, with successive passes iteratively refining the
sequence representation. (2) The Schema Engine, analogous to the HPC-PFC
"System 2" loop, dynamically extracts, ranks, and applies reusable schemas,
storing variable bindings in episodic memory and expanding them when needed. By
explicitly equipping the Transformer component of MIRAGE with actively managed
schematic structures, our model performs systematic compositional operations
through explicit schema application and transformation, relying solely on
frozen weights when solving entirely novel tasks. This approach demonstrates
systematic compositional generalization on the SCAN benchmark, achieving > 99%
accuracy on all task splits with only 1.19M parameters in the transformer
module. Ablation studies confirm that MIRAGE's systematicity critically depends
on the quality of extracted schemas and the model's iterative refinement
process.

</details>


### [44] [Success in Humanoid Reinforcement Learning under Partial Observation](https://arxiv.org/abs/2507.18883)
*Wuhao Wang,Zhiyong Chen*

Main category: cs.AI

TL;DR: This paper successfully trains humanoid policies under partial observability using a novel history encoder, achieving performance comparable to full-state methods.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of effective policy learning under partial observability in high-dimensional robotic tasks, particularly humanoid locomotion.

Method: Developing a history encoder that processes past observations in a fixed-length sequence, integrated into a standard model-free reinforcement learning algorithm.

Result: The approach enables stable training of humanoid policies with incomplete state information, achieving performance similar to full observability baselines and demonstrating adaptability to variations in robot properties.

Conclusion: The history encoder effectively reconstructs essential contextual information from past observations, facilitating robust decision-making under partial observability.

Abstract: Reinforcement learning has been widely applied to robotic control, but
effective policy learning under partial observability remains a major
challenge, especially in high-dimensional tasks like humanoid locomotion. To
date, no prior work has demonstrated stable training of humanoid policies with
incomplete state information in the benchmark Gymnasium Humanoid-v4
environment. The objective in this environment is to walk forward as fast as
possible without falling, with rewards provided for staying upright and moving
forward, and penalties incurred for excessive actions and external contact
forces. This research presents the first successful instance of learning under
partial observability in this environment. The learned policy achieves
performance comparable to state-of-the-art results with full state access,
despite using only one-third to two-thirds of the original states. Moreover,
the policy exhibits adaptability to robot properties, such as variations in
body part masses. The key to this success is a novel history encoder that
processes a fixed-length sequence of past observations in parallel. Integrated
into a standard model-free algorithm, the encoder enables performance on par
with fully observed baselines. We hypothesize that it reconstructs essential
contextual information from recent observations, thereby enabling robust
decision-making.

</details>


### [45] [Towards Improving Long-Tail Entity Predictions in Temporal Knowledge Graphs through Global Similarity and Weighted Sampling](https://arxiv.org/abs/2507.18977)
*Mehrnoosh Mirtaheri,Ryan A. Rossi,Sungchul Kim,Kanak Mahadik,Tong Yu,Xiang Chen,Mohammad Rostami*

Main category: cs.AI

TL;DR: An incremental training framework for Temporal Knowledge Graphs (TKGs) enhances existing methods by addressing evolving graphs, especially for unseen or sparse entities, resulting in significant performance improvements.


<details>
  <summary>Details</summary>
Motivation: Traditional TKG completion models assume full graph visibility during training, which neglects real-world challenges like evolving data and new entities with sparse connections.

Method: Combines a model-agnostic enhancement layer leveraging global entity similarity with a weighted sampling strategy focusing on infrequent entities, adaptable to any TKG method.

Result: Outperforms existing methods with up to 10-15% improvements in performance metrics on benchmark datasets, particularly benefiting long-tail or unseen entities.

Conclusion: The framework effectively mitigates catastrophic forgetting and improves the robustness of TKG completion in dynamic, incremental training environments.

Abstract: Temporal Knowledge Graph (TKG) completion models traditionally assume access
to the entire graph during training. This overlooks challenges stemming from
the evolving nature of TKGs, such as: (i) the model's requirement to generalize
and assimilate new knowledge, and (ii) the task of managing new or unseen
entities that often have sparse connections. In this paper, we present an
incremental training framework specifically designed for TKGs, aiming to
address entities that are either not observed during training or have sparse
connections. Our approach combines a model-agnostic enhancement layer with a
weighted sampling strategy, that can be augmented to and improve any existing
TKG completion method. The enhancement layer leverages a broader, global
definition of entity similarity, which moves beyond mere local neighborhood
proximity of GNN-based methods. The weighted sampling strategy employed in
training accentuates edges linked to infrequently occurring entities. We
evaluate our method on two benchmark datasets, and demonstrate that our
framework outperforms existing methods in total link prediction, inductive link
prediction, and in addressing long-tail entities. Notably, our method achieves
a 10\% improvement and a 15\% boost in MRR for these datasets. The results
underscore the potential of our approach in mitigating catastrophic forgetting
and enhancing the robustness of TKG completion methods, especially in an
incremental training context

</details>


### [46] [Fine-Grained Traffic Inference from Road to Lane via Spatio-Temporal Graph Node Generation](https://arxiv.org/abs/2507.19089)
*Shuhao Li,Weidong Yang,Yue Cui,Xiaoxing Liu,Lingkai Meng,Lipeng Ma,Fan Zhang*

Main category: cs.AI

TL;DR: The paper introduces FRTI, a method to infer detailed lane-level traffic data from limited road data, addressing sensor limitations with a two-stage framework called RoadDiff.


<details>
  <summary>Details</summary>
Motivation: Obtaining accurate lane-level traffic data is challenging due to sensor limitations and tracking inaccuracies, which impedes data-driven traffic management.

Method: They propose a two-stage framework, RoadDiff, utilizing a Road-Lane Correlation Autoencoder-Decoder and Lane Diffusion Module to infer fine-grained traffic states from limited data.

Result: Extensive experiments on six datasets validate the effectiveness of RoadDiff in addressing the FRTI task, demonstrating its potential for precise traffic management.

Conclusion: The proposed RoadDiff framework effectively infers detailed lane traffic information from limited data, offering a cost-effective solution for traffic management.

Abstract: Fine-grained traffic management and prediction are fundamental to key
applications such as autonomous driving, lane change guidance, and traffic
signal control. However, obtaining lane-level traffic data has become a
critical bottleneck for data-driven models due to limitations in the types and
number of sensors and issues with the accuracy of tracking algorithms. To
address this, we propose the Fine-grained Road Traffic Inference (FRTI) task,
which aims to generate more detailed lane-level traffic information using
limited road data, providing a more energy-efficient and cost-effective
solution for precise traffic management. This task is abstracted as the first
scene of the spatio-temporal graph node generation problem. We designed a
two-stage framework--RoadDiff--to solve the FRTI task. solve the FRTI task.
This framework leverages the Road-Lane Correlation Autoencoder-Decoder and the
Lane Diffusion Module to fully utilize the limited spatio-temporal dependencies
and distribution relationships of road data to accurately infer fine-grained
lane traffic states. Based on existing research, we designed several baseline
models with the potential to solve the FRTI task and conducted extensive
experiments on six datasets representing different road conditions to validate
the effectiveness of the RoadDiff model in addressing the FRTI task. The
relevant datasets and code are available at
https://github.com/ShuhaoLii/RoadDiff.

</details>


### [47] [Pareto-NRPA: A Novel Monte-Carlo Search Algorithm for Multi-Objective Optimization](https://arxiv.org/abs/2507.19109)
*Noé Lallouet,Tristan Cazenave,Cyrille Enderli*

Main category: cs.AI

TL;DR: Pareto-NRPA is a new multi-objective optimization algorithm extending NRPA for discrete problems, effectively balancing convergence and solution diversity.


<details>
  <summary>Details</summary>
Motivation: To adapt the single-objective NRPA algorithm for multi-objective optimization problems in discrete search spaces.

Method: Extends NRPA to handle multiple objectives using a set of policies, maintaining Pareto fronts during search and policy updates.

Result: Achieved competitive performance on bi-objective TSP with Time Windows and neural architecture search, outperforming state-of-the-art evolutionary algorithms especially in constrained spaces.

Conclusion: First adaptation of NRPA to multi-objective problems, demonstrating its effectiveness and opening new avenues for discrete multi-objective optimization.

Abstract: We introduce Pareto-NRPA, a new Monte-Carlo algorithm designed for
multi-objective optimization problems over discrete search spaces. Extending
the Nested Rollout Policy Adaptation (NRPA) algorithm originally formulated for
single-objective problems, Pareto-NRPA generalizes the nested search and policy
update mechanism to multi-objective optimization. The algorithm uses a set of
policies to concurrently explore different regions of the solution space and
maintains non-dominated fronts at each level of search. Policy adaptation is
performed with respect to the diversity and isolation of sequences within the
Pareto front. We benchmark Pareto-NRPA on two classes of problems: a novel
bi-objective variant of the Traveling Salesman Problem with Time Windows
problem (MO-TSPTW), and a neural architecture search task on well-known
benchmarks. Results demonstrate that Pareto-NRPA achieves competitive
performance against state-of-the-art multi-objective algorithms, both in terms
of convergence and diversity of solutions. Particularly, Pareto-NRPA strongly
outperforms state-of-the-art evolutionary multi-objective algorithms on
constrained search spaces. To our knowledge, this work constitutes the first
adaptation of NRPA to the multi-objective setting.

</details>


### [48] [OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?](https://arxiv.org/abs/2507.19132)
*Xuetian Chen,Yinghao Chen,Xinfeng Yuan,Zhuo Peng,Lu Chen,Yuekeng Li,Zhoujia Zhang,Yingqian Huang,Leyan Huang,Jiaqing Liang,Tianbao Xie,Zhiyong Wu,Qiushi Sun,Biqing Qi,Bowen Zhou*

Main category: cs.AI

TL;DR: OS-MAP is a comprehensive benchmark for evaluating computer-using agents across various tasks and capabilities, revealing current limitations and guiding future development.


<details>
  <summary>Details</summary>
Motivation: To address the mismatch in existing benchmarks that overlook task heterogeneity, agent capabilities, and real user demands, hindering progress and deployment.

Method: OS-MAP organizes 416 tasks across 15 applications using a five-level automation taxonomy and a demand hierarchy, enabling detailed performance and generalization analysis.

Result: State-of-the-art agents struggle with complex tasks involving perception and reasoning, indicating significant room for improvement.

Conclusion: Deeper understanding of current capabilities is essential to advance computer-using agent research and deployment.

Abstract: Computer-using agents have shown strong potential to boost human productivity
and enable new application forms across platforms. While recent advances have
led to usable applications, existing benchmarks fail to account for the
internal task heterogeneity and the corresponding agent capabilities, as well
as their alignment with actual user demands-hindering both targeted capability
development and the reliable transition of research progress into practical
deployment. To bridge the gap, we present OS-MAP, a benchmark for daily
computer-using automation that organizes its 416 realistic tasks across 15
applications along two key dimensions: a five-level taxonomy of automation and
a generalization scope derived from a real-world user demand hierarchy. To
enable fine-grained analysis of required capabilities and alignment with
real-world scenarios, OS-MAP evaluates agents along two dimensions: automation
level across a five-level taxonomy, and generalization scope across a demand
hierarchy. This design captures varying levels of required agent autonomy and
generalization, forming a performance-generalization evaluation matrix for
structured and comprehensive assessment. Experiments show that even
State-of-the-Art agents with VLM backbones struggle with higher-level tasks
involving perception, reasoning, and coordination-highlighting the need for a
deeper understanding of current strengths and limitations to drive the future
progress in computer-using agents research and deployment. All code,
environments, baselines, and data are publicly available at
https://github.com/OS-Copilot/OS-Map.

</details>


### [49] [PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring](https://arxiv.org/abs/2507.19172)
*Jiyao Wang,Xiao Yang,Qingyong Hu,Jiankai Tang,Can Liu,Dengbo He,Yuntao Wang,Yingcong Chen,Kaishun Wu*

Main category: cs.AI

TL;DR: PhysDrive is a large-scale multimodal dataset for contactless in-vehicle physiological sensing, covering various conditions and modalities to advance driver monitoring research.


<details>
  <summary>Details</summary>
Motivation: To address the scarcity of comprehensive datasets that reflect real-world driving challenges for physiological monitoring.

Method: Collecting synchronized multimodal data (RGB, near-infrared, mmWave radar) from 48 drivers under diverse driving conditions, with various biometric ground truths.

Result: Established a benchmark for signal-processing and deep-learning methods across multiple modalities using PhysDrive, and released open-source tools.

Conclusion: PhysDrive provides a valuable resource to accelerate research in driver monitoring and smart-cockpit systems.

Abstract: Robust and unobtrusive in-vehicle physiological monitoring is crucial for
ensuring driving safety and user experience. While remote physiological
measurement (RPM) offers a promising non-invasive solution, its translation to
real-world driving scenarios is critically constrained by the scarcity of
comprehensive datasets. Existing resources are often limited in scale, modality
diversity, the breadth of biometric annotations, and the range of captured
conditions, thereby omitting inherent real-world challenges in driving. Here,
we present PhysDrive, the first large-scale multimodal dataset for contactless
in-vehicle physiological sensing with dedicated consideration on various
modality settings and driving factors. PhysDrive collects data from 48 drivers,
including synchronized RGB, near-infrared camera, and raw mmWave radar data,
accompanied with six synchronized ground truths (ECG, BVP, Respiration, HR, RR,
and SpO2). It covers a wide spectrum of naturalistic driving conditions,
including driver motions, dynamic natural light, vehicle types, and road
conditions. We extensively evaluate both signal-processing and deep-learning
methods on PhysDrive, establishing a comprehensive benchmark across all
modalities, and release full open-source code with compatibility for mainstream
public toolboxes. We envision PhysDrive will serve as a foundational resource
and accelerate research on multimodal driver monitoring and smart-cockpit
systems.

</details>


### [50] [Faster Lifting for Ordered Domains with Predecessor Relations](https://arxiv.org/abs/2507.19182)
*Kuncheng Zou,Jiahao Mai,Yonggang Zhang,Yuyi Wang,Ondřej Kuželka,Yuanhong Wang,Yi Chang*

Main category: cs.AI

TL;DR: The paper presents a novel algorithm for lifted inference on ordered domains with predecessor relations, achieving significant speedups over existing methods.


<details>
  <summary>Details</summary>
Motivation: To improve the practical efficiency of lifted inference involving predecessor relations in ordered domains, which is challenging with existing WFOMC approaches.

Method: The authors develop an algorithm that natively incorporates predecessor relations, supporting general k-th predecessor relations and providing exponential speedup.

Result: The new algorithm outperforms previous methods, demonstrating up to a tenfold increase in speed across inference and combinatorial tasks.

Conclusion: Native support for predecessor relations in lifted inference algorithms leads to substantial efficiency gains, facilitating practical applications.

Abstract: We investigate lifted inference on ordered domains with predecessor
relations, where the elements of the domain respect a total (cyclic) order, and
every element has a distinct (clockwise) predecessor. Previous work has
explored this problem through weighted first-order model counting (WFOMC),
which computes the weighted sum of models for a given first-order logic
sentence over a finite domain. In WFOMC, the order constraint is typically
encoded by the linear order axiom introducing a binary predicate in the
sentence to impose a linear ordering on the domain elements. The immediate and
second predecessor relations are then encoded by the linear order predicate.
Although WFOMC with the linear order axiom is theoretically tractable, existing
algorithms struggle with practical applications, particularly when the
predecessor relations are involved. In this paper, we treat predecessor
relations as a native part of the axiom and devise a novel algorithm that
inherently supports these relations. The proposed algorithm not only provides
an exponential speedup for the immediate and second predecessor relations,
which are known to be tractable, but also handles the general k-th predecessor
relations. The extensive experiments on lifted inference tasks and
combinatorics math problems demonstrate the efficiency of our algorithm,
achieving speedups of a full order of magnitude.

</details>


### [51] [Knowledge Grafting: A Mechanism for Optimizing AI Model Deployment in Resource-Constrained Environments](https://arxiv.org/abs/2507.19261)
*Osama Almurshed,Ashish Kaushal,Asmail Muftah,Nitin Auluck,Omer Rana*

Main category: cs.AI

TL;DR: Introduces knowledge grafting, a technique to reduce AI model size by transferring features from a large model to a smaller one, maintaining high accuracy and enabling deployment on resource-limited devices.


<details>
  <summary>Details</summary>
Motivation: The need to deploy large AI models in resource-constrained environments motivates the development of more efficient models.

Method: Transferring selected features (scion) from a large donor model to a smaller rootstock model to optimize model size and performance.

Result: Achieved 88.54% reduction in size, improved generalization, and maintained high accuracy (around 90%) on unseen data.

Conclusion: Knowledge grafting effectively balances size and performance, facilitating AI deployment in hardware-limited scenarios.

Abstract: The increasing adoption of Artificial Intelligence (AI) has led to larger,
more complex models with numerous parameters that require substantial computing
power -- resources often unavailable in many real-world application scenarios.
Our paper addresses this challenge by introducing knowledge grafting, a novel
mechanism that optimizes AI models for resource-constrained environments by
transferring selected features (the scion) from a large donor model to a
smaller rootstock model. The approach achieves an 88.54% reduction in model
size (from 64.39 MB to 7.38 MB), while improving generalization capability of
the model. Our new rootstock model achieves 89.97% validation accuracy (vs.
donor's 87.47%), maintains lower validation loss (0.2976 vs. 0.5068), and
performs exceptionally well on unseen test data with 90.45% accuracy. It
addresses the typical size vs performance trade-off, and enables deployment of
AI frameworks on resource-constrained devices with enhanced performance. We
have tested our approach on an agricultural weed detection scenario, however,
it can be extended across various edge computing scenarios, potentially
accelerating AI adoption in areas with limited hardware/software support -- by
mirroring in a similar manner the horticultural grafting enables productive
cultivation in challenging agri-based environments.

</details>


### [52] [Modeling Uncertainty: Constraint-Based Belief States in Imperfect-Information Games](https://arxiv.org/abs/2507.19263)
*Achille Morenville,Éric Piette*

Main category: cs.AI

TL;DR: Constraint-based belief states in imperfect-information games perform comparably to probabilistic methods, simplifying decision-making.


<details>
  <summary>Details</summary>
Motivation: To explore effective belief representation methods in imperfect-information games.

Method: Comparing constraint-based and probabilistic belief models using general-purpose agents across two games.

Result: Constraint-based beliefs perform similarly to probabilistic beliefs, with minimal performance differences.

Conclusion: Constraint-based belief states may be sufficient for effective decision-making, simplifying the modeling process.

Abstract: In imperfect-information games, agents must make decisions based on partial
knowledge of the game state. The Belief Stochastic Game model addresses this
challenge by delegating state estimation to the game model itself. This allows
agents to operate on externally provided belief states, thereby reducing the
need for game-specific inference logic. This paper investigates two approaches
to represent beliefs in games with hidden piece identities: a constraint-based
model using Constraint Satisfaction Problems and a probabilistic extension
using Belief Propagation to estimate marginal probabilities. We evaluated the
impact of both representations using general-purpose agents across two
different games. Our findings indicate that constraint-based beliefs yield
results comparable to those of probabilistic inference, with minimal
differences in agent performance. This suggests that constraint-based belief
states alone may suffice for effective decision-making in many settings.

</details>


### [53] [Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges](https://arxiv.org/abs/2507.19364)
*Patrick Taillandier,Jean Daniel Zucker,Arnaud Grignard,Benoit Gaudou,Nghi Quang Huynh,Alexis Drogoul*

Main category: cs.AI

TL;DR: This paper evaluates the potential and limitations of using Large Language Models in social simulation, reviewing cognitive capabilities, applications, challenges, and suggesting hybrid modeling approaches.


<details>
  <summary>Details</summary>
Motivation: To explore how LLMs can be employed in social simulation and identify their benefits and drawbacks.

Method: Literature review of recent findings on LLMs in cognition and social inference, analysis of applications like multi-agent frameworks, and discussion of hybrid modeling solutions.

Result: Identified both capabilities and limitations of LLMs in social tasks, highlighted key projects and challenges, and proposed hybrid models for better integration.

Conclusion: Advocates for hybrid systems combining LLMs with traditional agent-based models to leverage their strengths while mitigating weaknesses.

Abstract: This position paper examines the use of Large Language Models (LLMs) in
social simulation, analyzing both their potential and their limitations from a
computational social science perspective. The first part reviews recent
findings on the ability of LLMs to replicate key aspects of human cognition,
including Theory of Mind reasoning and social inference, while also
highlighting significant limitations such as cognitive biases, lack of true
understanding, and inconsistencies in behavior. The second part surveys
emerging applications of LLMs in multi-agent simulation frameworks, focusing on
system architectures, scale, and validation strategies. Notable projects such
as Generative Agents (Smallville) and AgentSociety are discussed in terms of
their design choices, empirical grounding, and methodological innovations.
Particular attention is given to the challenges of behavioral fidelity,
calibration, and reproducibility in large-scale LLM-driven simulations. The
final section distinguishes between contexts where LLMs, like other black-box
systems, offer direct value-such as interactive simulations and serious
games-and those where their use is more problematic, notably in explanatory or
predictive modeling. The paper concludes by advocating for hybrid approaches
that integrate LLMs into traditional agent-based modeling platforms (GAMA,
Netlogo, etc), enabling modelers to combine the expressive flexibility of
language-based reasoning with the transparency and analytical rigor of
classical rule-based systems.

</details>


### [54] [Learning neuro-symbolic convergent term rewriting systems](https://arxiv.org/abs/2507.19372)
*Flavio Petruzzellis,Alberto Testolin,Alessandro Sperduti*

Main category: cs.AI

TL;DR: The paper introduces a neuro-symbolic framework for learning convergent term rewriting systems, demonstrating superior generalization, efficiency, and versatility in solving mathematical and multi-domain tasks, outperforming state-of-the-art models.


<details>
  <summary>Details</summary>
Motivation: Address the challenge of neural systems learning symbolic algorithms with strong generalization and out-of-distribution performance.

Method: Propose modular neural architectures (NRS and FastNRS) inspired by rewriting algorithms, emphasizing algorithmic design and architectural enhancements.

Result: Both models generalize well out-of-distribution, with FastNRS offering efficiency benefits; they outperform neural baselines and match or surpass recent powerful models in reasoning tasks.

Conclusion: The proposed neuro-symbolic approach effectively learns symbolic algorithms, exhibiting robustness, efficiency, and versatility across multiple domains.

Abstract: Building neural systems that can learn to execute symbolic algorithms is a
challenging open problem in artificial intelligence, especially when aiming for
strong generalization and out-of-distribution performance. In this work, we
introduce a general framework for learning convergent term rewriting systems
using a neuro-symbolic architecture inspired by the rewriting algorithm itself.
We present two modular implementations of such architecture: the Neural
Rewriting System (NRS) and the Fast Neural Rewriting System (FastNRS). As a
result of algorithmic-inspired design and key architectural elements, both
models can generalize to out-of-distribution instances, with FastNRS offering
significant improvements in terms of memory efficiency, training speed, and
inference time. We evaluate both architectures on four tasks involving the
simplification of mathematical formulas and further demonstrate their
versatility in a multi-domain learning scenario, where a single model is
trained to solve multiple types of problems simultaneously. The proposed system
significantly outperforms two strong neural baselines: the Neural Data Router,
a recent transformer variant specifically designed to solve algorithmic
problems, and GPT-4o, one of the most powerful general-purpose large-language
models. Moreover, our system matches or outperforms the latest o1-preview model
from OpenAI that excels in reasoning benchmarks.

</details>


### [55] [Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset Management Under Budget Constraints](https://arxiv.org/abs/2507.19458)
*Amir Fard,Arnold X. -X. Yuan*

Main category: cs.AI

TL;DR: A hierarchical deep reinforcement learning method enhances multi-year infrastructure planning by decomposing budget and maintenance decisions, improving scalability and solution quality.


<details>
  <summary>Details</summary>
Motivation: To address the complexity and scalability issues in infrastructure asset management due to combinatorial actions, asset deterioration, budget constraints, and environmental uncertainties.

Method: A two-level hierarchical framework combining a high-level Budget Planner with a low-level Maintenance Planner within a hierarchical Soft Actor-Critic, integrating linear programming for feasibility.

Result: The approach outperforms traditional methods like Deep Q-Learning and genetic algorithms in convergence speed, scalability, and solution quality across sewer network cases.

Conclusion: The hierarchical deep RL methodology offers an efficient, scalable, and near-optimal solution for multi-year infrastructure planning challenges.

Abstract: Budget planning and maintenance optimization are crucial for infrastructure
asset management, ensuring cost-effectiveness and sustainability. However, the
complexity arising from combinatorial action spaces, diverse asset
deterioration, stringent budget constraints, and environmental uncertainty
significantly limits existing methods' scalability. This paper proposes a
Hierarchical Deep Reinforcement Learning methodology specifically tailored to
multi-year infrastructure planning. Our approach decomposes the problem into
two hierarchical levels: a high-level Budget Planner allocating annual budgets
within explicit feasibility bounds, and a low-level Maintenance Planner
prioritizing assets within the allocated budget. By structurally separating
macro-budget decisions from asset-level prioritization and integrating linear
programming projection within a hierarchical Soft Actor-Critic framework, the
method efficiently addresses exponential growth in the action space and ensures
rigorous budget compliance. A case study evaluating sewer networks of varying
sizes (10, 15, and 20 sewersheds) illustrates the effectiveness of the proposed
approach. Compared to conventional Deep Q-Learning and enhanced genetic
algorithms, our methodology converges more rapidly, scales effectively, and
consistently delivers near-optimal solutions even as network size grows.

</details>
